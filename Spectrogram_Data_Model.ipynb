{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_qGuPcj-aNmh"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from PIL import Image, ImageDraw\n",
    "from PIL import ImagePath\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import shutil\n",
    "import librosa\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rn\n",
    "from sklearn.metrics import f1_score \n",
    "from prettytable import PrettyTable\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, GlobalAveragePooling1D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HDBcl_PUaNmp"
   },
   "outputs": [],
   "source": [
    "recordings_path = os.getcwd() + '\\\\recordings'\n",
    "\n",
    "file_names = os.listdir(recordings_path)\n",
    "\n",
    "all_files = [(recordings_path + '\\\\' + i) for i in file_names]\n",
    "labels = [i[0][0] for i in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NYYpfqoaNmv"
   },
   "source": [
    "<font size=4>Grader function 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2oJSOmYBaNmx",
    "outputId": "d4509e7d-1cb6-4e7f-e469-ef40314a8510"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_files():\n",
    "    temp = len(all_files)==2000\n",
    "    temp1 = all([x[-3:]==\"wav\" for x in all_files])\n",
    "    temp = temp and temp1\n",
    "    return temp\n",
    "grader_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhvSIN6raNm3"
   },
   "source": [
    "Create a dataframe(name=df_audio) with two columns(path, label).   \n",
    "You can get the label from the first letter of name.  \n",
    "Eg: 0_jackson_0 --> 0  \n",
    "0_jackson_43 --> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fWP6vXBeaNm3"
   },
   "outputs": [],
   "source": [
    "#Create a dataframe(name=df_audio) with two columns(path, label).   \n",
    "#You can get the label from the first letter of name.  \n",
    "#Eg: 0_jackson_0 --> 0  \n",
    "#0_jackson_43 --> 0\n",
    "file_dict = {'path':all_files,'label':labels}\n",
    "\n",
    "df_audio = pd.DataFrame(file_dict)\n",
    "\n",
    "df_audio = shuffle(df_audio, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5ZpuaGuJaNm8",
    "outputId": "76da0fb5-2033-49ef-eba7-880c395cf87a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 766 to 1044\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   path    2000 non-null   object\n",
      " 1   label   2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 46.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#info\n",
    "df_audio.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOKpYJ_LaNnD"
   },
   "source": [
    "<font size=4>Grader function 2 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7Q8r_T8-aNnE",
    "outputId": "849e3f3e-e77c-492c-ba29-77508e74fc57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_df():\n",
    "    flag_shape = df_audio.shape==(2000,2)\n",
    "    flag_columns = all(df_audio.columns==['path', 'label'])\n",
    "    list_values = list(df_audio.label.value_counts())\n",
    "    flag_label = len(list_values)==10\n",
    "    flag_label2 = all([i==200 for i in list_values])\n",
    "    final_flag = flag_shape and flag_columns and flag_label and flag_label2\n",
    "    return final_flag\n",
    "grader_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PlfssCc3aNnL"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_audio = shuffle(df_audio, random_state=33)#don't change the random state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ448aENaNnR"
   },
   "source": [
    "<pre><font size=4>Train and Validation split</font></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vSPy-Ln6aNnS"
   },
   "outputs": [],
   "source": [
    "X = df_audio['path']\n",
    "y = df_audio['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, \n",
    "                                                    random_state=45, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPK3sbzUaNnW"
   },
   "source": [
    "<font size=4>Grader function 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "chZzntKUaNnX",
    "outputId": "e2949c8b-2f00-434f-8403-56b577faf04f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_split():\n",
    "    flag_len = (len(X_train)==1400) and (len(X_test)==600) and (len(y_train)==1400) and (len(y_test)==600)\n",
    "    values_ytrain = list(y_train.value_counts())\n",
    "    flag_ytrain = (len(values_ytrain)==10) and (all([i==140 for i in values_ytrain]))\n",
    "    values_ytest = list(y_test.value_counts())\n",
    "    flag_ytest = (len(values_ytest)==10) and (all([i==60 for i in values_ytest]))\n",
    "    final_flag = flag_len and flag_ytrain and flag_ytest\n",
    "    return final_flag\n",
    "grader_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([int(i) for i in y_train])\n",
    "y_test = np.array([int(i) for i in y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGhh-39vaNnb"
   },
   "source": [
    "<pre><font size=4>Preprocessing</font>\n",
    "\n",
    "All files are in the \"WAV\" format. We will read those raw data files using the librosa</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "i99JacQSaNnc"
   },
   "outputs": [],
   "source": [
    "sample_rate = 22050\n",
    "def load_wav(x, get_duration=True):\n",
    "    samples, sample_rate = librosa.load(x, sr=22050)\n",
    "    if get_duration:\n",
    "        duration = librosa.get_duration(samples, sample_rate)\n",
    "        return [samples, duration]\n",
    "    else:\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Rx97f8GGaNnh"
   },
   "outputs": [],
   "source": [
    "train_wav = X_train.apply(lambda x: load_wav(x))\n",
    "samples = [i[0] for i in train_wav]\n",
    "duration = [i[1] for i in train_wav]\n",
    "train_index = list(X_train.index)\n",
    "train_dict = {'raw_data':samples, 'duration':duration}\n",
    "X_train_processed = pd.DataFrame(train_dict, index=train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wav = X_test.apply(lambda x: load_wav(x))\n",
    "samples = [i[0] for i in test_wav]\n",
    "duration = [i[1] for i in test_wav]\n",
    "test_index = list(X_test.index)\n",
    "test_dict = {'raw_data':samples, 'duration':duration}\n",
    "X_test_processed = pd.DataFrame(test_dict, index=test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "duQZPQevaNno",
    "outputId": "05986007-6321-4b26-99f6-2197b1811a24"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X_train_processed['duration'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wE5SDRzSaNns",
    "outputId": "f2501a90-2a43-43db-f02c-1463defe2146"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X_test_processed['duration'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vvLhm1AqaNny",
    "outputId": "a4430992-0f16-4d24-de92-0a6fcec1df06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th percentile is 0.1435374149659864\n",
      "10 th percentile is 0.2582630385487528\n",
      "20 th percentile is 0.2996371882086168\n",
      "30 th percentile is 0.33207256235827665\n",
      "40 th percentile is 0.3596371882086168\n",
      "50 th percentile is 0.39045351473922907\n",
      "60 th percentile is 0.4171156462585034\n",
      "70 th percentile is 0.4465850340136054\n",
      "80 th percentile is 0.4846530612244898\n",
      "90 th percentile is 0.5528934240362812\n",
      "100 th percentile is 2.282766439909297\n"
     ]
    }
   ],
   "source": [
    "#print 0 to 100 percentile values with step size of 10 for train data duration. \n",
    "for i in range(0,101, 10):\n",
    "    print(i,'th percentile is', np.percentile(X_train_processed['duration'], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rSlVQh4CaNn2",
    "outputId": "d6970436-db83-4d01-c910-7ebe92baab41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 th percentile is 0.5528934240362812\n",
      "91 th percentile is 0.5619047619047619\n",
      "92 th percentile is 0.5760671201814062\n",
      "93 th percentile is 0.5941251700680278\n",
      "94 th percentile is 0.6120943310657596\n",
      "95 th percentile is 0.6330226757369615\n",
      "96 th percentile is 0.6447981859410431\n",
      "97 th percentile is 0.6647700680272108\n",
      "98 th percentile is 0.6956090702947844\n",
      "99 th percentile is 0.8072766439909297\n",
      "100 th percentile is 2.282766439909297\n"
     ]
    }
   ],
   "source": [
    "##print 90 to 100 percentile values with step size of 1. \n",
    "for i in range(90,101, 1):\n",
    "    print(i,'th percentile is', np.percentile(X_train_processed['duration'], i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbMb4Y0RaNoA"
   },
   "source": [
    "<font size=4>Grader function 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UMoyLLSAaNoF",
    "outputId": "cfb3ad33-3dc0-49e7-d078-8619b164b5db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_processed():\n",
    "    flag_columns = (all(X_train_processed.columns==['raw_data', 'duration'])) and (all(X_test_processed.columns==['raw_data', 'duration']))\n",
    "    flag_shape = (X_train_processed.shape ==(1400, 2)) and (X_test_processed.shape==(600,2))\n",
    "    return flag_columns and flag_shape\n",
    "grader_processed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cux3_jfcaNoM"
   },
   "source": [
    "<pre>Based on our analysis 99 percentile values are less than 0.8sec so we will limit maximum length of X_train_processed and X_test_processed to 0.8 sec. It is similar to pad_sequence for a text dataset. \n",
    "\n",
    "While loading the audio files, we are using sampling rate of 22050 so one sec will give array of length 22050. so, our maximum length is 0.8*22050 = 17640\n",
    "\n",
    "Pad with Zero if length of sequence is less than 17640 else Truncate the number. \n",
    "\n",
    "Also create a masking vector for train and test. \n",
    "\n",
    "masking vector value = 1 if it is real value, 0 if it is pad value. Masking vector data type must be bool.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "voqSEyvcaNoO"
   },
   "outputs": [],
   "source": [
    "max_length  = 17640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 17640)\n",
      "(1400, 17640)\n"
     ]
    }
   ],
   "source": [
    "X_train_pad_seq = []\n",
    "X_train_mask = []\n",
    "for i in train_index:\n",
    "    length = len(X_train_processed.loc[i, 'raw_data'])\n",
    "    value = X_train_processed.loc[i, 'raw_data']\n",
    "    if (length >= max_length):\n",
    "        X_train_pad_seq.append(value[0:max_length])\n",
    "        X_train_mask.append(np.ones(max_length))\n",
    "    else:\n",
    "        zero_pad = np.zeros(max_length - length)\n",
    "        mask_one_padd = np.ones(length - 1)\n",
    "        mask_zero_padd = np.zeros((max_length - length) + 1)\n",
    "        X_train_pad_seq.append(np.concatenate((value, zero_pad)))\n",
    "        X_train_mask.append(np.concatenate((mask_one_padd, mask_zero_padd)))\n",
    "        \n",
    "X_train_pad_seq = np.array(X_train_pad_seq)\n",
    "X_train_mask = np.array(X_train_mask)\n",
    "X_train_mask = X_train_mask.astype('bool')\n",
    "\n",
    "print(X_train_pad_seq.shape)\n",
    "print(X_train_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.46304616e-05 -1.03010592e-04 -1.59132222e-04 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-7.36712292e-03 -9.12982132e-03 -9.19409655e-03 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-5.02168259e-04  2.75946519e-07  2.25390177e-04 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-5.44477371e-04 -1.69934088e-03 -4.19601100e-03 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-9.29699093e-03 -1.09779211e-02 -1.10168587e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "\n",
      "[[ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pad_seq[0:5])\n",
    "print('\\n')\n",
    "print(X_train_mask[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 17640)\n",
      "(600, 17640)\n"
     ]
    }
   ],
   "source": [
    "X_test_pad_seq = []\n",
    "X_test_mask = []\n",
    "for i in test_index:\n",
    "    length = len(X_test_processed.loc[i, 'raw_data'])\n",
    "    value = X_test_processed.loc[i, 'raw_data']\n",
    "    if (length > max_length):\n",
    "        X_test_pad_seq.append(value[0:max_length])\n",
    "        X_test_mask.append(np.ones(max_length))\n",
    "    else:\n",
    "        zero_pad = np.zeros(max_length - length)\n",
    "        mask_one_padd = np.ones(length - 1)\n",
    "        mask_zero_padd = np.zeros((max_length - length) + 1)\n",
    "        X_test_pad_seq.append(np.concatenate((value, zero_pad)))\n",
    "        X_test_mask.append(np.concatenate((mask_one_padd, mask_zero_padd)))\n",
    "        \n",
    "X_test_pad_seq = np.array(X_test_pad_seq)\n",
    "X_test_mask = np.array(X_test_mask)\n",
    "X_test_mask = X_test_mask.astype('bool')\n",
    "\n",
    "print(X_test_pad_seq.shape)\n",
    "print(X_test_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.69634663e-04  6.73947972e-04  4.90176899e-04 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 2.60761619e-04  7.77264213e-05 -1.72803571e-04 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 2.98726615e-02  3.13351192e-02  2.78438795e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-3.59053840e-04 -9.80457116e-05  3.04512709e-04 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 9.44157597e-03  1.12675084e-02  1.14977006e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "\n",
      "[[ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_pad_seq[0:5])\n",
    "print('\\n')\n",
    "print(X_test_mask[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEHMgm4DaNoe"
   },
   "source": [
    "<font size=4>Grader function 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Th3KhplGaNof",
    "outputId": "5e783ec9-81d2-4156-9e88-efdee0ff8b2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_padoutput():\n",
    "    flag_padshape = (X_train_pad_seq.shape==(1400, 17640)) and (X_test_pad_seq.shape==(600, 17640)) and (y_train.shape==(1400,))\n",
    "    flag_maskshape = (X_train_mask.shape==(1400, 17640)) and (X_test_mask.shape==(600, 17640)) and (y_test.shape==(600,))\n",
    "    flag_dtype = (X_train_mask.dtype==bool) and (X_test_mask.dtype==bool)\n",
    "    return flag_padshape and flag_maskshape and flag_dtype\n",
    "grader_padoutput()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Fwk0X4zaNpR"
   },
   "source": [
    "### 2. Converting into spectrogram and giving spectrogram data as input  \n",
    "<pre>\n",
    "We can use librosa to convert raw data into spectrogram. A spectrogram shows the features in a two-dimensional representation with the\n",
    "intensity of a frequency at a point in time i.e we are converting Time domain to frequency domain. you can read more about this in https://pnsn.org/spectrograms/what-is-a-spectrogram\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "nb5AGzTjaNpS"
   },
   "outputs": [],
   "source": [
    "def convert_to_spectrogram(raw_data):\n",
    "    '''converting to spectrogram'''\n",
    "    spectrum = librosa.feature.melspectrogram(y=raw_data, sr=sample_rate, n_mels=64)\n",
    "    logmel_spectrum = librosa.power_to_db(S=spectrum, ref=np.max)\n",
    "    return logmel_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "B__rN4RjaNpc"
   },
   "outputs": [],
   "source": [
    "X_train_spectrogram = []\n",
    "for i in range(X_train_pad_seq.shape[0]):\n",
    "    X_train_spectrogram.append(convert_to_spectrogram(X_train_pad_seq[i]))\n",
    "\n",
    "X_test_spectrogram = []\n",
    "for i in range(X_test_pad_seq.shape[0]):\n",
    "    X_test_spectrogram.append(convert_to_spectrogram(X_test_pad_seq[i]))\n",
    "\n",
    "X_train_spectrogram = np.array(X_train_spectrogram)\n",
    "X_test_spectrogram = np.array(X_test_spectrogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr1ynYZnaNpj"
   },
   "source": [
    "<font size=4>Grader function 6 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "oniXBXcsaNpk",
    "outputId": "0f94ec35-98af-4b98-c501-35cbbfbd0a2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_spectrogram():\n",
    "    flag_shape = (X_train_spectrogram.shape==(1400,64, 35)) and (X_test_spectrogram.shape == (600, 64, 35))\n",
    "    return flag_shape\n",
    "grader_spectrogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxlEVyIYaNpt"
   },
   "source": [
    "<pre>\n",
    "Now we have\n",
    "\n",
    "Train data: X_train_spectrogram and y_train  \n",
    "Test data: X_test_spectrogram and y_test   \n",
    "\n",
    "We will create a LSTM model which takes this input. \n",
    "\n",
    "Task:\n",
    "\n",
    "1. Create an LSTM network which takes \"X_train_spectrogram\" as input and has to return output at every time step. \n",
    "2. Average the output of every time step and give this to the Dense layer of any size. \n",
    "(ex: Output from LSTM will be  (#., time_steps, features) average the output of every time step i.e, you should get (#.,time_steps) \n",
    "and then pass to dense layer )\n",
    "3. give the above output to Dense layer of size 10( output layer) and train the network with sparse categorical cross entropy.  \n",
    "4. Use tensorboard to plot the graphs of loss and metric(use micro F1 score as metric) and histograms of gradients. \n",
    "5. make sure that it won't overfit. \n",
    "6. You are free to include any regularization\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "IaQjaiiGaNpv"
   },
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(0)\n",
    "rn.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "862fP2e-aNp3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Layer (InputLayer)        [(None, 64, 35)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_Layer (LSTM)               (None, 64, 25)       6100        Input_Layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           LSTM_Layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Mask_Input_Layer (InputLayer)   [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Output (Dense)                  (None, 10)           650         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,750\n",
      "Trainable params: 6,750\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ = tf.keras.Input(shape=(64, 35), name='Input_Layer')\n",
    "mask_input = tf.keras.Input(shape=(64), name='Mask_Input_Layer')\n",
    "lstm = LSTM(25, return_sequences=True, kernel_regularizer=regularizers.l2(1e-4), \n",
    "            name='LSTM_Layer')(input_)\n",
    "global_avg = GlobalAveragePooling1D(data_format='channels_first')(lstm)\n",
    "drop = Dropout(rate=0.2)(global_avg)\n",
    "output = tf.keras.layers.Dense(10, activation='softmax', name='Output')(drop)\n",
    "model = Model(inputs=[input_, mask_input], outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "VtMsbGs3aNp_"
   },
   "outputs": [],
   "source": [
    "class F1Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_data, validation, target):   \n",
    "        super(F1Metrics, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.validation_data = validation\n",
    "        self.target = target\n",
    "\n",
    "  \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        predict = self.model.predict(self.train_data[0])\n",
    "        predict = np.argmax(predict, axis=1)\n",
    "        \n",
    "        val_predict = self.model.predict(self.validation_data[0])\n",
    "        val_predict = np.argmax(val_predict, axis=1)\n",
    "\n",
    "        target = self.train_data[1]\n",
    "        val_target = self.validation_data[1]\n",
    "        \n",
    "        f1 = f1_score(target, predict, average='micro')\n",
    "        val_f1 = f1_score(val_target, val_predict, average='micro')\n",
    "\n",
    "        pt = PrettyTable()\n",
    "        pt.field_names = ['Epoch', 'Loss', 'Validation Loss', 'Accuracy', \n",
    "                          'Validation Accuracy', 'F1', 'F1_Val']\n",
    "        pt.add_row([(epoch+1), np.round(logs['loss'], 4), np.round(logs['val_loss'], 4), \n",
    "                    np.round(logs['acc'], 4), np.round(logs['val_acc'], 4), \n",
    "                    f1, val_f1])\n",
    "        print(pt)\n",
    "        if (f1 >= self.target and val_f1 > self.target):\n",
    "            self.model.stop_training = True\n",
    "            print(\"F1 score reached the target\")   \n",
    "        return\n",
    "    \n",
    "f1 = F1Metrics((X_train_spectrogram, y_train), (X_test_spectrogram, y_test), 0.801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.9\n",
    "    epochs_drop = 50\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    print('Learning Rate ->', lrate)\n",
    "    return lrate\n",
    "\n",
    "lr_reducer = tf.keras.callbacks.LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Log folder is deleted\n",
      "New Log folder is created\n"
     ]
    }
   ],
   "source": [
    "# Reference: Assignment\n",
    "log_path = os.getcwd() + '\\\\logs'\n",
    "if(path.exists(log_path)):\n",
    "    shutil.rmtree(log_path)\n",
    "    print('Old Log folder is deleted')\n",
    "\n",
    "%reload_ext tensorboard\n",
    "\n",
    "log_dir = log_path\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\n",
    "print('New Log folder is created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='sparse_categorical_crossentropy', \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 64) for input Tensor(\"Mask_Input_Layer:0\", shape=(None, 64), dtype=float32), but it was called on an input with incompatible shape (None, 17640).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 64) for input Tensor(\"Mask_Input_Layer:0\", shape=(None, 64), dtype=float32), but it was called on an input with incompatible shape (None, 17640).\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.127927). Check your callbacks.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 64) for input Tensor(\"Mask_Input_Layer:0\", shape=(None, 64), dtype=float32), but it was called on an input with incompatible shape (None, 17640).\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   1   | 2.3076 |      2.3002     |  0.105   |        0.1517       | 0.12357142857142857 | 0.15166666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "|   2   | 2.2995 |      2.2933     |  0.1129  |         0.17        | 0.13357142857142856 |  0.17  |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "|   3   | 2.2942 |      2.2896     |  0.1343  |         0.18        | 0.15357142857142858 |  0.18  |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   4   | 2.291 |      2.2847     |  0.1329  |        0.1683       | 0.15428571428571428 | 0.16833333333333333 |\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "|   5   | 2.2879 |      2.281      |  0.1336  |        0.1767       | 0.1657142857142857 | 0.17666666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "|   6   | 2.2826 |      2.2772     |  0.145   |        0.1767       | 0.1657142857142857 | 0.17666666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "|   7   | 2.2792 |      2.2751     |  0.1579  |         0.17        | 0.16142857142857142 |  0.17  |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   8   | 2.277 |      2.2717     |  0.1557  |        0.1733       | 0.16642857142857143 | 0.17333333333333334 |\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+-------+-----------------+----------+---------------------+------+---------------------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |  F1  |        F1_Val       |\n",
      "+-------+-------+-----------------+----------+---------------------+------+---------------------+\n",
      "|   9   | 2.275 |      2.2682     |  0.1471  |        0.1983       | 0.17 | 0.19833333333333333 |\n",
      "+-------+-------+-----------------+----------+---------------------+------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   10  | 2.2725 |      2.2654     |  0.1464  |        0.1817       | 0.18642857142857142 | 0.18166666666666664 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|   11  | 2.2681 |      2.2618     |  0.1686  |        0.195        | 0.1792857142857143 | 0.195  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   12  | 2.2655 |      2.2572     |  0.1686  |         0.2         | 0.18142857142857147 | 0.20000000000000004 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   13  | 2.2644 |      2.253      |  0.155   |        0.2183       | 0.18071428571428572 | 0.21833333333333332 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   14  | 2.258 |      2.2517     |  0.1721  |        0.2083       | 0.18642857142857142 | 0.20833333333333334 |\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "|   15  | 2.2534 |      2.2439     |  0.175   |        0.2083       | 0.2007142857142857 | 0.20833333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "|   16  | 2.2502 |      2.2413     |  0.185   |         0.23        | 0.19714285714285715 |  0.23  |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   17  | 2.2388 |      2.2311     |  0.1914  |        0.2217       | 0.20000000000000004 | 0.22166666666666668 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   18  | 2.2382 |      2.2269     |  0.1886  |        0.2267       | 0.20999999999999996 | 0.22666666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "|   19  | 2.2307 |      2.2216     |  0.1886  |        0.2267       | 0.1985714285714286 | 0.22666666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "|   20  | 2.2241 |      2.2156     |  0.1929  |        0.2317       | 0.2235714285714286 | 0.23166666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "|   21  | 2.2186 |      2.2094     |  0.2036  |        0.235        | 0.22428571428571428 | 0.235  |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   22  | 2.2139 |      2.2042     |  0.2064  |        0.2383       | 0.22071428571428572 | 0.23833333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   23  | 2.2068 |      2.1979     |  0.1914  |        0.2583       | 0.21214285714285713 | 0.25833333333333336 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "|   24  | 2.1967 |      2.1903     |  0.2057  |        0.275        | 0.24214285714285713 | 0.275  |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+------+---------------------+\n",
      "|   25  | 2.1913 |      2.187      |  0.2293  |        0.2717       | 0.23 | 0.27166666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   26  | 2.1889 |      2.1793     |  0.2179  |        0.2767       | 0.24357142857142858 | 0.27666666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   27  | 2.1828 |      2.1725     |  0.2164  |        0.2917       | 0.2507142857142857 | 0.2916666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "|   28  | 2.1759 |      2.166      |  0.2321  |        0.2883       | 0.2407142857142857 | 0.28833333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "|   29  | 2.1691 |      2.1571     |  0.235   |        0.285        | 0.24642857142857144 | 0.285  |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   30  | 2.1628 |      2.1491     |  0.2357  |        0.2917       | 0.2407142857142857 | 0.2916666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|   31  | 2.1574 |      2.1437     |  0.2429  |         0.31        | 0.2664285714285714 |  0.31  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|   32  | 2.1498 |      2.1361     |  0.2629  |        0.305        | 0.2664285714285714 | 0.305  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|   33  | 2.1433 |      2.1298     |  0.2579  |         0.31        | 0.2735714285714286 |  0.31  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   34  | 2.1378 |      2.1124     |   0.26   |        0.3317       | 0.30357142857142855 | 0.33166666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   35  | 2.1242 |      2.1107     |  0.2743  |        0.3467       | 0.2985714285714286 | 0.3466666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   36  | 2.115 |      2.0965     |   0.29   |        0.3483       | 0.31285714285714283 | 0.34833333333333333 |\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   37  | 2.1012 |      2.084      |   0.28   |        0.355        | 0.32285714285714284 | 0.35500000000000004 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "|   38  | 2.0895 |      2.0761     |  0.3021  |        0.355        | 0.3242857142857143 | 0.35500000000000004 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   39  | 2.0847 |      2.0708     |  0.3007  |        0.3283       | 0.2978571428571429 | 0.3283333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |   F1  |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+---------------------+\n",
      "|   40  | 2.0698 |      2.0482     |  0.3121  |        0.3683       | 0.345 | 0.36833333333333335 |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   41  | 2.0536 |      2.0284     |  0.3129  |        0.3533       | 0.32071428571428573 | 0.35333333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "|   42  | 2.0402 |      2.0186     |  0.3029  |        0.375        | 0.34714285714285714 | 0.375  |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "|   43  | 2.0279 |      2.0062     |  0.3207  |        0.3633       | 0.33285714285714285 | 0.3633333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "|   44  | 2.0116 |      1.9864     |  0.325   |        0.3717       | 0.3485714285714286 | 0.37166666666666665 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "|   45  | 1.9954 |      1.9706     |  0.3329  |         0.38        | 0.35 |  0.38  |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   46  | 1.9754 |      1.9567     |   0.34   |        0.3767       | 0.34714285714285714 | 0.37666666666666665 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "|   47  | 1.9649 |      1.9479     |  0.3307  |        0.3683       | 0.3335714285714286 | 0.36833333333333335 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "+-------+-------+-----------------+----------+---------------------+------+---------------------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |  F1  |        F1_Val       |\n",
      "+-------+-------+-----------------+----------+---------------------+------+---------------------+\n",
      "|   48  | 1.961 |      1.9349     |  0.3336  |        0.385        | 0.35 | 0.38499999999999995 |\n",
      "+-------+-------+-----------------+----------+---------------------+------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "|   49  | 1.9526 |      1.9224     |   0.34   |        0.3883       | 0.35214285714285715 | 0.3883333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "|   50  | 1.9356 |      1.9112     |   0.35   |        0.3983       | 0.3585714285714286 | 0.39833333333333326 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "|   51  | 1.9248 |      1.9015     |  0.3643  |        0.3933       | 0.36357142857142855 | 0.3933333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+--------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |          F1         | F1_Val |\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+--------+\n",
      "|   52  | 1.915 |      1.8846     |  0.3479  |        0.405        | 0.37285714285714283 | 0.405  |\n",
      "+-------+-------+-----------------+----------+---------------------+---------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "|   53  | 1.8997 |      1.8754     |  0.3671  |         0.39        | 0.36642857142857144 |  0.39  |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |   F1  | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------+\n",
      "|   54  | 1.8866 |      1.8651     |  0.3686  |        0.405        | 0.375 | 0.405  |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "|   55  | 1.8738 |      1.8585     |  0.3779  |        0.3933       | 0.37714285714285717 | 0.3933333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |   F1  |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "|   56  | 1.8654 |      1.8438     |  0.3807  |        0.4083       | 0.375 | 0.4083333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   57  | 1.8566 |      1.8355     |  0.3871  |        0.4117       | 0.3871428571428571 | 0.4116666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "|   58  | 1.8378 |      1.8204     |  0.3979  |        0.405        | 0.38 | 0.405  |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "|   59  | 1.8294 |      1.8105     |  0.3879  |        0.4233       | 0.3942857142857143 | 0.42333333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   60  | 1.8202 |      1.7979     |  0.3764  |        0.4067       | 0.3842857142857143 | 0.4066666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   61  | 1.8109 |      1.7885     |  0.3857  |        0.4317       | 0.39785714285714285 | 0.43166666666666664 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|   62  | 1.8023 |      1.7847     |  0.3857  |        0.435        | 0.4157142857142857 | 0.435  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   63  | 1.7906 |      1.763      |  0.4157  |        0.4467       | 0.42214285714285715 | 0.44666666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "|   64  | 1.7688 |      1.7483     |  0.4186  |        0.4483       | 0.41214285714285714 | 0.4483333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "|   65  | 1.7665 |      1.7382     |  0.4236  |        0.465        | 0.43357142857142855 | 0.465  |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   66  | 1.7525 |      1.7264     |  0.4214  |        0.4617       | 0.43642857142857144 | 0.46166666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   67  | 1.7336 |      1.7217     |  0.4486  |        0.475        | 0.45785714285714285 | 0.47500000000000003 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "|   68  | 1.7356 |      1.708      |  0.4271  |        0.4883       | 0.4664285714285714 | 0.48833333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   69  | 1.7182 |      1.6957     |  0.4357  |        0.4783       | 0.45785714285714285 | 0.47833333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "|   70  | 1.7044 |      1.6901     |  0.4514  |        0.4917       | 0.4757142857142857 | 0.49166666666666664 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   71  | 1.6951 |      1.6811     |  0.4536  |        0.4883       | 0.47642857142857137 | 0.48833333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "|   72  | 1.6922 |      1.6847     |   0.46   |        0.5017       | 0.49714285714285716 | 0.5016666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   73  | 1.6884 |      1.6654     |  0.4521  |        0.4783       | 0.46714285714285714 | 0.47833333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "|   74  | 1.6674 |      1.6535     |  0.4764  |         0.49        | 0.47928571428571426 |  0.49  |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |          F1         |        F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "|   75  | 1.6665 |      1.6504     |  0.4671  |        0.4917       | 0.49142857142857144 | 0.49166666666666664 |\n",
      "+-------+--------+-----------------+----------+---------------------+---------------------+---------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |   F1  |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "|   76  | 1.6609 |      1.6394     |  0.4664  |        0.5067       | 0.495 | 0.5066666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|   77  | 1.6472 |      1.6306     |  0.4729  |        0.535        | 0.5157142857142857 | 0.535  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|   78  | 1.6369 |      1.6231     |  0.4793  |        0.535        | 0.5207142857142857 | 0.535  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|   79  | 1.6252 |      1.6129     |   0.49   |        0.515        | 0.5142857142857142 | 0.515  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|   80  | 1.6212 |      1.6084     |  0.4786  |        0.515        | 0.5085714285714286 | 0.515  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|   81  | 1.6149 |      1.5986     |  0.4814  |         0.53        | 0.5178571428571429 |  0.53  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|   82  | 1.6056 |      1.5867     |  0.4929  |        0.525        | 0.5207142857142857 | 0.525  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   83  | 1.6018 |      1.5875     |  0.5036  |        0.5683       | 0.5464285714285714 | 0.5683333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   84  | 1.5843 |      1.5714     |   0.52   |        0.5217       | 0.5114285714285715 | 0.5216666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|   85  | 1.5753 |      1.5662     |  0.5264  |        0.545        | 0.5292857142857142 | 0.545  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   86  | 1.5718 |      1.5565     |   0.52   |        0.5417       | 0.5435714285714286 | 0.5416666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |   F1  | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------+\n",
      "|   87  | 1.5639 |      1.5521     |   0.53   |        0.585        | 0.565 | 0.585  |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   88  | 1.5568 |      1.5447     |  0.525   |        0.5533       | 0.5507142857142857 | 0.5533333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   89  | 1.5442 |      1.5289     |  0.5336  |        0.5633       | 0.5542857142857143 | 0.5633333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|   90  | 1.5356 |      1.525      |  0.5279  |         0.56        | 0.5521428571428572 |  0.56  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|   91  | 1.5299 |      1.5162     |   0.53   |        0.575        | 0.5514285714285714 | 0.575  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   92  | 1.5148 |      1.5044     |  0.5464  |        0.5933       | 0.5828571428571429 | 0.5933333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   93  | 1.5049 |      1.4959     |  0.5486  |        0.5983       | 0.5857142857142857 | 0.5983333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   94  | 1.4997 |      1.4874     |  0.5407  |        0.5683       | 0.5642857142857143 | 0.5683333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   95  | 1.4938 |      1.4747     |   0.54   |        0.5933       | 0.5814285714285714 | 0.5933333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   96  | 1.4777 |      1.471      |  0.5586  |        0.6183       | 0.5928571428571429 | 0.6183333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |   F1  |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "|   97  | 1.4669 |      1.4669     |  0.5636  |        0.5983       | 0.595 | 0.5983333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   98  | 1.4733 |      1.4641     |  0.5586  |        0.5933       | 0.5785714285714286 | 0.5933333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|   99  | 1.4604 |      1.4513     |  0.575   |        0.5967       | 0.5907142857142857 | 0.5966666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  100  | 1.4606 |      1.4378     |  0.5593  |        0.6183       | 0.5978571428571429 | 0.6183333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |   F1  |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "|  101  | 1.4519 |      1.4345     |  0.5621  |        0.6083       | 0.615 | 0.6083333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  102  | 1.4394 |      1.4291     |  0.5757  |        0.5967       | 0.5985714285714285 | 0.5966666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  103  | 1.4378 |      1.4205     |  0.5714  |        0.6067       | 0.5907142857142857 | 0.6066666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  104  | 1.4308 |      1.4135     |  0.5629  |         0.61        | 0.6035714285714285 |  0.61  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  105  | 1.4153 |      1.4058     |  0.595   |         0.63        | 0.6185714285714285 |  0.63  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  106  | 1.4076 |      1.4026     |  0.5864  |        0.6033       | 0.6021428571428571 | 0.6033333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  107  | 1.4072 |      1.391      |  0.5821  |        0.625        | 0.6078571428571429 | 0.625  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  108  | 1.3994 |      1.3902     |  0.5886  |        0.6317       | 0.6107142857142858 | 0.6316666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  109  | 1.3903 |      1.3792     |  0.5964  |        0.6333       | 0.6114285714285714 | 0.6333333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  110  | 1.393 |      1.3763     |  0.5971  |         0.63        | 0.6128571428571429 |  0.63  |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  111  | 1.3704 |      1.3657     |  0.6036  |        0.6333       | 0.6321428571428571 | 0.6333333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  112  | 1.3695 |      1.3569     |  0.5979  |        0.6383       | 0.6178571428571429 | 0.6383333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  113  | 1.3621 |      1.3518     |  0.6107  |        0.6483       | 0.6371428571428571 | 0.6483333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  114  | 1.3482 |      1.3425     |  0.6107  |        0.6517       | 0.6364285714285715 | 0.6516666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "|  115  | 1.3433 |      1.3378     |  0.6086  |        0.6283       | 0.63 | 0.6283333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "|  116  | 1.3466 |      1.3264     |  0.5957  |        0.665        | 0.65 | 0.665  |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  117  | 1.3333 |      1.3214     |  0.6193  |        0.655        | 0.6421428571428571 | 0.655  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  118  | 1.3244 |       1.32      |  0.6136  |        0.655        | 0.6514285714285715 | 0.655  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  119  | 1.3104 |      1.3069     |  0.6364  |        0.6583       | 0.6471428571428571 | 0.6583333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |   F1  |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "|  120  | 1.3063 |      1.3005     |  0.625   |        0.6767       | 0.655 | 0.6766666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  121  | 1.3048 |      1.2944     |  0.6314  |        0.6733       | 0.6628571428571428 | 0.6733333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  122  | 1.2982 |      1.2904     |  0.6379  |         0.68        | 0.6664285714285715 |  0.68  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  123  | 1.2924 |      1.2919     |  0.6407  |        0.6733       | 0.6571428571428571 | 0.6733333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  124  | 1.2764 |      1.2762     |  0.6429  |        0.6783       | 0.6728571428571428 | 0.6783333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  125  | 1.2746 |      1.2677     |  0.6471  |        0.6817       | 0.6735714285714286 | 0.6816666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  126  | 1.2628 |      1.2653     |  0.6457  |        0.6817       | 0.6735714285714286 | 0.6816666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  127  | 1.2639 |      1.2569     |  0.6407  |        0.6733       | 0.6721428571428572 | 0.6733333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  128  | 1.2579 |      1.2522     |  0.6521  |        0.685        | 0.6764285714285714 | 0.685  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  129  | 1.2531 |      1.244      |  0.655   |        0.6933       | 0.6821428571428572 | 0.6933333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  130  | 1.2415 |      1.2421     |  0.6507  |        0.6867       | 0.6792857142857143 | 0.6866666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "|  131  | 1.2425 |      1.2416     |  0.6621  |        0.6967       | 0.69 | 0.6966666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  132  | 1.2368 |      1.2343     |   0.65   |        0.6883       | 0.6792857142857143 | 0.6883333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  133  | 1.2286 |      1.2282     |  0.6593  |        0.6933       | 0.6978571428571428 | 0.6933333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  134  | 1.234 |      1.2179     |  0.6493  |         0.68        | 0.6864285714285714 |  0.68  |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  135  | 1.2133 |      1.2133     |   0.66   |        0.6883       | 0.6892857142857143 | 0.6883333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "|  136  | 1.2151 |      1.208      |  0.6586  |        0.705        | 0.69 | 0.705  |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  137  | 1.2105 |       1.2       |  0.655   |        0.7067       | 0.7014285714285714 | 0.7066666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  138  | 1.2019 |      1.1955     |  0.6671  |        0.7017       | 0.6985714285714286 | 0.7016666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  139  | 1.1965 |      1.2035     |  0.6886  |        0.7033       | 0.7057142857142857 | 0.7033333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  140  | 1.1891 |      1.1877     |  0.6757  |         0.71        | 0.7078571428571427 | 0.7100000000000001 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  141  | 1.1782 |      1.1794     |  0.6707  |        0.7083       | 0.7100000000000001 | 0.7083333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  142  | 1.1777 |      1.1763     |  0.675   |        0.715        | 0.7078571428571427 | 0.715  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  143  | 1.1668 |      1.1698     |  0.6907  |        0.7117       | 0.7171428571428572 | 0.7116666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  144  | 1.1727 |      1.1652     |  0.675   |        0.7133       | 0.7028571428571428 | 0.7133333333333335 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  145  | 1.1621 |      1.1725     |  0.6771  |        0.715        | 0.7121428571428571 | 0.715  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  146  | 1.1624 |      1.1592     |  0.6764  |        0.6967       | 0.7071428571428572 | 0.6966666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  147  | 1.1565 |      1.1589     |  0.6914  |        0.6833       | 0.7007142857142857 | 0.6833333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  148  | 1.1468 |      1.1492     |  0.6886  |        0.725        | 0.7271428571428571 | 0.7250000000000001 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  149  | 1.1423 |      1.1411     |  0.6921  |         0.72        | 0.7185714285714285 |  0.72  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "|  150  | 1.1376 |      1.1361     |  0.6979  |        0.7117       | 0.72 | 0.7116666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  151  | 1.1333 |      1.1397     |  0.6943  |        0.7033       | 0.7100000000000001 | 0.7033333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  152  | 1.129 |      1.1297     |  0.6957  |        0.7217       | 0.7264285714285714 | 0.7216666666666668 |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  153  | 1.1229 |      1.1214     |  0.7029  |        0.7167       | 0.7314285714285713 | 0.7166666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  154  | 1.1206 |      1.1185     |  0.7071  |        0.7267       | 0.7307142857142858 | 0.7266666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  155  | 1.1123 |      1.1152     |  0.6979  |        0.7367       | 0.7314285714285713 | 0.7366666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1        |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "|  156  | 1.1145 |      1.1155     |  0.6993  |        0.7183       | 0.717857142857143 | 0.7183333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  157  | 1.1042 |      1.102      |  0.7014  |        0.7283       | 0.7357142857142858 | 0.7283333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  158  | 1.0968 |      1.0983     |  0.7021  |        0.7217       | 0.7321428571428571 | 0.7216666666666668 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  159  | 1.0849 |      1.0949     |  0.7136  |        0.725        | 0.7428571428571429 | 0.7250000000000001 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  160  | 1.1014 |      1.0931     |  0.705   |        0.7317       | 0.7292857142857143 | 0.7316666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  161  | 1.078 |      1.0828     |  0.7064  |        0.7317       | 0.7378571428571428 | 0.7316666666666667 |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  162  | 1.0822 |      1.0808     |  0.6929  |        0.7183       | 0.7328571428571429 | 0.7183333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |   F1  |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "|  163  | 1.0672 |      1.0764     |  0.7186  |        0.7383       | 0.745 | 0.7383333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  164  | 1.0799 |      1.0801     |  0.6979  |        0.7417       | 0.7442857142857143 | 0.7416666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  165  | 1.0667 |      1.0733     |  0.7164  |        0.7283       | 0.7371428571428572 | 0.7283333333333334 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  166  | 1.0568 |      1.0654     |  0.7193  |        0.725        | 0.7514285714285714 | 0.7250000000000001 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  167  | 1.0643 |      1.0723     |   0.7    |        0.705        | 0.7342857142857143 | 0.705  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  168  | 1.0535 |      1.0577     |  0.715   |        0.7433       | 0.7428571428571429 | 0.7433333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  169  | 1.0459 |      1.0536     |  0.7121  |        0.7317       | 0.7435714285714285 | 0.7316666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "|  170  | 1.0399 |      1.046      |  0.7143  |        0.735        | 0.74 | 0.735  |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  171  | 1.0384 |      1.0365     |  0.7171  |        0.7333       | 0.7492857142857143 | 0.7333333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  172  | 1.0406 |      1.0416     |  0.6993  |         0.73        | 0.7471428571428572 | 0.7299999999999999 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  173  | 1.0276 |      1.0324     |  0.7329  |        0.7383       | 0.7492857142857143 | 0.7383333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  174  | 1.0258 |      1.0311     |  0.7186  |        0.7317       | 0.7535714285714286 | 0.7316666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  175  | 1.0154 |      1.0289     |  0.715   |        0.745        | 0.7542857142857143 | 0.745  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  176  | 1.014 |      1.0227     |  0.7236  |        0.7433       | 0.7478571428571429 | 0.7433333333333333 |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  177  | 1.0144 |      1.0185     |   0.73   |        0.7333       | 0.7542857142857143 | 0.7333333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+-------+-----------------+----------+---------------------+-------+--------------------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |   F1  |       F1_Val       |\n",
      "+-------+-------+-----------------+----------+---------------------+-------+--------------------+\n",
      "|  178  | 0.999 |      1.0248     |  0.7229  |        0.7233       | 0.755 | 0.7233333333333334 |\n",
      "+-------+-------+-----------------+----------+---------------------+-------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "|  179  | 1.0133 |      1.016      |  0.7143  |         0.72        | 0.75 |  0.72  |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  180  | 0.9956 |      0.9994     |  0.7286  |         0.75        | 0.7607142857142857 |  0.75  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  181  | 0.9899 |      1.0053     |  0.7286  |        0.7483       | 0.7564285714285715 | 0.7483333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  182  | 0.9893 |      0.9997     |  0.7364  |        0.7317       | 0.7592857142857142 | 0.7316666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  183  | 0.9806 |      0.9985     |  0.7421  |        0.7433       | 0.7671428571428571 | 0.7433333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1        |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "|  184  | 0.9844 |      0.9921     |  0.7407  |        0.7517       | 0.762857142857143 | 0.7516666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  185  | 0.9772 |      0.9949     |  0.7236  |         0.74        | 0.7635714285714286 |  0.74  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "|  186  | 0.9804 |      0.9937     |   0.73   |        0.725        | 0.76 | 0.7250000000000001 |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  187  | 0.9745 |      0.9786     |  0.7407  |        0.7517       | 0.7699999999999999 | 0.7516666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1        |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "|  188  | 0.9647 |      0.9777     |  0.745   |        0.7483       | 0.762142857142857 | 0.7483333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  189  | 0.959 |      0.9709     |  0.7407  |        0.7517       | 0.7657142857142857 | 0.7516666666666667 |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  190  | 0.9537 |      0.9705     |  0.7307  |        0.745        | 0.7592857142857142 | 0.745  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  191  | 0.9518 |      0.965      |  0.7371  |        0.7483       | 0.7592857142857142 | 0.7483333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1        |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "|  192  | 0.9524 |      0.9706     |  0.7236  |        0.7317       | 0.762142857142857 | 0.7316666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  193  | 0.9416 |      0.9653     |  0.7471  |         0.74        | 0.7721428571428571 |  0.74  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  194  | 0.9488 |      0.9593     |  0.7429  |         0.74        | 0.7678571428571429 |  0.74  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+------+-----------------+----------+---------------------+------+--------+\n",
      "| Epoch | Loss | Validation Loss | Accuracy | Validation Accuracy |  F1  | F1_Val |\n",
      "+-------+------+-----------------+----------+---------------------+------+--------+\n",
      "|  195  | 0.95 |      0.9571     |  0.735   |         0.75        | 0.76 |  0.75  |\n",
      "+-------+------+-----------------+----------+---------------------+------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  196  | 0.9433 |      0.9443     |  0.7429  |        0.755        | 0.7742857142857142 | 0.755  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  197  | 0.9299 |      0.9508     |  0.7536  |        0.7517       | 0.7714285714285715 | 0.7516666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  198  | 0.9172 |      0.9548     |  0.7543  |        0.7483       | 0.7707142857142857 | 0.7483333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  199  | 0.9228 |      0.9361     |  0.7493  |        0.7617       | 0.7742857142857142 | 0.7616666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "|  200  | 0.9124 |      0.9359     |  0.7629  |        0.755        | 0.78 | 0.755  |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  201  | 0.9134 |      0.9355     |  0.7486  |        0.7483       | 0.7771428571428571 | 0.7483333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  202  | 0.9123 |      0.9285     |  0.7464  |         0.76        | 0.7814285714285715 |  0.76  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  203  | 0.907 |      0.9434     |  0.7586  |        0.7483       | 0.7735714285714286 | 0.7483333333333333 |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |   F1  |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "|  204  | 0.9105 |      0.9228     |  0.7543  |        0.7617       | 0.785 | 0.7616666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+-------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  205  | 0.9014 |      0.922      |  0.7679  |        0.765        | 0.7792857142857142 | 0.765  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  206  | 0.8995 |      0.918      |  0.7571  |        0.7683       | 0.7842857142857141 | 0.7683333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  207  | 0.8964 |      0.9103     |  0.7607  |        0.7783       | 0.7864285714285715 | 0.7783333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  208  | 0.8956 |      0.9135     |  0.7521  |        0.7767       | 0.7842857142857141 | 0.7766666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  209  | 0.8961 |      0.9064     |  0.7543  |        0.765        | 0.7878571428571427 | 0.765  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  210  | 0.8827 |      0.9034     |  0.755   |         0.77        | 0.7878571428571427 | 0.7699999999999999 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  211  | 0.8798 |      0.9096     |  0.7664  |        0.7567       | 0.7792857142857142 | 0.7566666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  212  | 0.8675 |      0.8947     |  0.7614  |        0.7783       | 0.7907142857142857 | 0.7783333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  213  | 0.8692 |      0.9031     |   0.77   |        0.7817       | 0.7885714285714286 | 0.7816666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1        |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "|  214  | 0.8791 |      0.9023     |  0.7543  |        0.7533       | 0.787142857142857 | 0.7533333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  215  | 0.8629 |      0.8907     |  0.765   |        0.7767       | 0.7964285714285714 | 0.7766666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  216  | 0.8624 |      0.8979     |  0.7721  |        0.7717       | 0.7857142857142857 | 0.7716666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  217  | 0.8702 |      0.8821     |  0.7536  |        0.7667       | 0.7935714285714286 | 0.7666666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  218  | 0.8655 |      0.8839     |  0.7736  |        0.785        | 0.7907142857142857 | 0.785  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  219  | 0.8613 |      0.8845     |  0.7657  |         0.78        | 0.7864285714285715 |  0.78  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1        |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "|  220  | 0.8534 |      0.8687     |  0.7686  |        0.7833       | 0.797142857142857 | 0.7833333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  221  | 0.8568 |      0.8721     |  0.7579  |        0.7683       | 0.7978571428571428 | 0.7683333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  222  | 0.8502 |      0.8771     |  0.7571  |        0.7783       | 0.7992857142857143 | 0.7783333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  223  | 0.8386 |      0.8644     |  0.7786  |        0.7817       | 0.7978571428571428 | 0.7816666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  224  | 0.8331 |      0.8671     |  0.7821  |        0.7767       | 0.7914285714285715 | 0.7766666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  225  | 0.8443 |      0.877      |  0.7593  |        0.7733       | 0.8028571428571428 | 0.7733333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  226  | 0.8471 |      0.8619     |  0.7714  |        0.785        | 0.8078571428571428 | 0.785  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  227  | 0.827 |      0.8503     |  0.7907  |        0.785        | 0.7935714285714286 | 0.785  |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "|  228  | 0.8229 |      0.8535     |  0.7764  |         0.78        | 0.79 |  0.78  |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  229  | 0.8199 |      0.8505     |  0.7686  |         0.78        | 0.7978571428571428 |  0.78  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  230  | 0.8267 |      0.8764     |  0.7586  |        0.7467       | 0.7907142857142857 | 0.7466666666666667 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1        | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------+\n",
      "|  231  | 0.8143 |      0.8584     |  0.7743  |        0.765        | 0.792142857142857 | 0.765  |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1        | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------+\n",
      "|  232  | 0.8089 |      0.8479     |  0.7771  |        0.765        | 0.797142857142857 | 0.765  |\n",
      "+-------+--------+-----------------+----------+---------------------+-------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  233  | 0.8151 |      0.8275     |  0.7721  |        0.7833       | 0.8028571428571428 | 0.7833333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  234  | 0.7909 |      0.8355     |  0.7886  |        0.7817       | 0.8078571428571428 | 0.7816666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  235  | 0.801 |      0.8331     |  0.7793  |        0.7883       | 0.8057142857142857 | 0.7883333333333333 |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  236  | 0.8038 |       0.83      |  0.7779  |        0.785        | 0.8042857142857143 | 0.785  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  237  | 0.8004 |      0.8232     |  0.7657  |        0.7917       | 0.8085714285714286 | 0.7916666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  238  | 0.7937 |      0.8239     |  0.7857  |        0.7783       | 0.8121428571428572 | 0.7783333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  239  | 0.7901 |      0.8148     |  0.7857  |        0.7883       | 0.8128571428571428 | 0.7883333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  240  | 0.7853 |      0.8174     |  0.7857  |        0.7783       | 0.8085714285714286 | 0.7783333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  241  | 0.778 |      0.8262     |  0.7829  |        0.7683       | 0.8028571428571428 | 0.7683333333333333 |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "|  242  | 0.7768 |      0.8155     |  0.7829  |        0.7833       | 0.81 | 0.7833333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  243  | 0.7754 |      0.8067     |  0.7914  |        0.7983       | 0.8157142857142857 | 0.7983333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  244  | 0.7626 |      0.8072     |  0.795   |        0.7833       | 0.8128571428571428 | 0.7833333333333333 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |  F1  |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "|  245  | 0.7666 |      0.803      |  0.7886  |        0.7767       | 0.82 | 0.7766666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+------+--------------------+\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  246  | 0.762 |      0.799      |   0.8    |        0.795        | 0.8128571428571428 | 0.795  |\n",
      "+-------+-------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  247  | 0.7686 |      0.7975     |  0.7921  |        0.7967       | 0.8178571428571428 | 0.7966666666666665 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         | F1_Val |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "|  248  | 0.7742 |      0.7971     |  0.7793  |        0.785        | 0.8242857142857143 | 0.785  |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------+\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "| Epoch |  Loss  | Validation Loss | Accuracy | Validation Accuracy |         F1         |       F1_Val       |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "|  249  | 0.7677 |      0.7971     |  0.7893  |        0.8017       | 0.8207142857142857 | 0.8016666666666666 |\n",
      "+-------+--------+-----------------+----------+---------------------+--------------------+--------------------+\n",
      "F1 score reached the target\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x130d0ceec48>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #train your model\n",
    "model.fit(x = [X_train_spectrogram, X_train_mask], y=y_train, epochs=1000, batch_size=32, \n",
    "          validation_data=([X_test_spectrogram, X_test_mask], y_test),\n",
    "          callbacks = [f1, tensorboard_callback], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAJ6CAYAAADgnjdsAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAALZVSURBVHhe7f0HdBxXnqcLanbPmbNnXvfM7pmz7+3M6zezPWemd3bm1dRU9XbX1HSr1NVSqaokValLJa+SK3lXoqdEUaToJYqiRMrQiKQMKXrRiqI3ovfegyRAEqAFCXrQAPxv/m7mTQWSkYlAIoCE+b5zvoPMiPiHy0zg/vLeCNx0setNhoiIiIiI2JIk6CAiIiIiYouToIOIiIiIiC1Ogg4iIiIiIrY4CTqIiIiIiNjiJOggIiIiImKLk6CDiIiIiIgtToIOIiIiIiK2OAk6iIiIiIjY4iToICIiIiJii5Ogg4iIiIiILU6CDiIiIiIitjgJOoiIiIiI2OIk6CAiIiIiYoszctC59MFf2bWVH9i1TV9md8Mou/zV3aH1hbZy2P+wa+uG1dzf9SPsyteP26Vefx5a09Bq+6Jq/4LQ+YiIiIiImJ+Rg87lUf9o18+WuoZ5Vqqu2NXFPUPrC+2VyY/a9cvnUjtak+vnj9qVKX8MrWtICTqIiIiIiA1j9B6dXn9ul8f93gUGWbVtomukXy/fm552ZeLDVjn4v4TWF9p00Lly3q4u7OaeX533ul0/VeSOo/rIxkbv2SHoICIiIiI2jHlfo+Mb6dXHd9ww71L/v7Cry/pbddkG57XVH7lpmnd1bie7tvEzF4qurf80ETA2WXXxEhc80vWJwKGeoerDq918DTPT0DM/X14e+zur2vOtVR/dYlVFc2vUa/ichtFd/a6fXVsx0KpL1ya2+bkLOjK4rLajnij1VqnXStNy7b/38ue/tKodU9z2tZ9X53ZOByV3jIl9vjLrT1a1c5pV7ZtvlUP+pkZN1dZxdm3zGHcOW1PQURCu2v1N4nU4mzjwq4mguc+uzHjBzdP50zkJm+e9uqSPXb940v300yo/vdmqT+62ql0zaiwbVOf4+ukDdvnLX6enXZ3fJbGu8vT74vq5I+79ov1w+7LpC7t+6VTiTX7Nzbu66K0a62wINZSyau/sxHtqjftcXF3cyy72+BdW+fGPEu+dr626ZKmz6sAiu7ZykFV++IN07aV3/51VbRnr1GM/Xe9HX+dqi+Yk3puvJrc35Y/J54EeTS2vaZc/v90uvfcf3JDV6uLv3Ptc7+fL4+5NL9sQ6rNTY19nt3PnQPNq7G9i2tVFPdy50Ply06c96/Zbj4PH7NWx3XA+Eu8bnXetP3jsoctNeiS5j4n3iV4PvS567repGvc7J1CXrk8sf3X+G9/vv+q+vCP5uup3XeIcX10+wC71+1+/35fEsQU/A8HtFuq1kf65f19qvzLnZ9u/zPOaPj+p857rnMhsnxG//fQ6E/P0t6Zy2E/TtW6ZNZ+417Jy+P9MT3Pvq/0Lb/js6Mu9qn3zCnrOERExf2MPOmrIVh/dbHb9upvvSDzWNNfITTQ4HVcvJX+muH7ptPtjowZmdcmyZP21y+nl1CD1jQM1cu1apZueJtEYVZhx81PhxVld5X7qD1JY0Lm2dkhi5dWuoazrkJL7vyW10u+5XlGSbiTrD6vbL+3jlQvJbSQeV+2c6uZnHqNC1NV5ryV+HnbP0yT2WbSmoKOGhM6LQu6V6c9b9Yld6ZBZtW3CjfPOH0ufd/feOLLRnbNgD5wfVpntPCpU6/2l11mvt5/u3idXzruGz5Vv27pArPecpl9d+rZ7j1Xtmu7ed9UHl9v1yopEQ/qZGuuO08sTHnQNtGsbRtrlMb91+1F9aKVrGCooK9in5yX2T/O0777+ypQn3TSpx3761QVvuvVq39Vw0zrcMt+8kjzPmpf4mbm8Gpz6rFUfXJGY1jXZ6Ns+2e2H9scvH7fqLdYXAm5f1ajU9hOBRvOC+6v9d+cg0cjWOdFxVR1YnPh8P5ZuMLtpRXPdudVzfb6D50PnSZ9b1enLkxrHHrZcotGrBrJrLAfOg5bXsqpxX2oknqvOTUu8Vnqu96nbZ60zsf/J13RW8j2W2Gf9XtGx+tDgtl+23i3jtxPcbsFem4T+efIYEu/L1PswOD/b/ikYuPOReE302rj3tJ7rNVNgzHFOcn1G0tvXeyexPoVKhZ2qrePT4eXyF79KBuPEZ109+pom3fvq0Cq37svj70tPd+8/9xoU7pwjImL+xh50XENWwebYVtcLI7WMvqHXH3wfAm6Yn0DrvDLzZRcerp855BoGrnGbaGQK/fFTo1eNXzVCry59x21TP13wSTRar8x40f3x80FHjZMrXz+RDBqJkKP9UANaYeb66f0upKgRnP5DGbb/icdCfwQVhhSKXLBa/VFy+wu7u+1fv3A88cf3N+ljVM/DteXvJf8gFs1x08LW26qCTqJhc/3CCXdO9FyvjW4SoYbk9Ypi14jwy7oel8RrrdfTL6uwoYaHC76JAKPptQUdNYrUM6NhisGApPXqPZFefyIA67neh9onvQ+vfNvGzXO9hOuGN+jNNty39YlGmBpjeq7G2bVVg93+ZTYoZWaj0zeC9W23Gmh+erDxrueVI37mGuxaPhgcwpbXe1w9kjrHmqf3t16XYE9S3N5wXIljcQEjsd/B/dV+6EsR/z6oHHGLa9zqZ7o2EAz8tMzzUWOdgXmZy6lHTw1nvT6Z69UyWlY1fjth02psSz0bid9twVCqkO/X67afaJD7MOfmB7bbFF6bzPdlcH5t+5dZK2s7J7k+I3qeuX+Zr5OGLatefxeubfnq+55CvS4KRYl5/rOj/VTPj1u+gOccERHzN9agoxDgrnlJBIyrS3rfsKwaoj4EaJqf76fpp4KKAsv1yjOJP169bhgypmEMChkKK77BKtVAFurV0R897UNwGd+I9b0w7vHVi+65CzqJsJJt/9Ph69wRu/zZL9LT9e2wGln64+n2ObFObSd9jKkeJv2BVCPerTf1B1kGz4uf1tJVg0JhRedeDQjfQ+J6XRKvub59zazxKoQqTKr3RcFFzzU9V9DxwdR9K5xopGgbeo9pnnuf+B4dvW6JIJ0M0PoGPhGo1QOn91HpOjd8Kvh+awg1bC/YKAuqaa5RmPr2+8rMl5JDcxKNQDd/+P90YeDqd32TjcFUz4PmZTbYNWzNfQuua9XUwEucG/V4ajilc8+s9PIupB9Y7Bqf19YOdb0efp8ayszGqsKmCzTqWQkEBXfMiXOib+I1ZMkNK0s1XL2ZDV3pz4fW53uC3PGOv6/GuXKPNTxJ39pvm+Cm6z2kbWSuNyzUhE0L7r9rNKvR/tlt6fk3bD+1TQ2VUm9GcLuFem20L+n3ip7rs5XYLz/fv3a17V/6PZ2qlbWdk1yfEem2n+rRUY+QQr+GnSkQSTfMTsOaFagUWlO9N3o9XMhJ/E6u2j3TBRf1vrmQk/idVMhzjoiI+Rtr0PENzmyoByMdArIEHTUm9cfKD+tyPS6JkKAGnOZlCwf6Y+Snp4NOYN980PFhxE+/uuxdt6zrOXDDy0pvWEbf2qmB7adfmfQHdxMGF5oC3BB0Usfoz0vmerMdS0v38sh/SLzGE1yPl4aTuWusEo1OnR8fDjNVIyPY46OfCqUKMrmCjho0Wq8Csn8dfZjy75M0VVddI8gHGgVZvUbqXXTDG1PDL4Prj9Ngg8o17srWJ4fNJD4PvlHop8lrm0env0l2DTc1Bsff71QjzvdGBdfl1DVrOs73/kOy4Z0j6Ki+8pO/dte76fy62lRj3+933AYby9IFHX3Ln9jXYFDQPB2Djs/tc2LfFH41zddmDTrB86EQlQiO6XmpY3ePFQgT7x39/tF63LUdiXXFEnS0DgXSET9Lz79h+3qsxnWi8a5zol7F4HYL8dpEDToy1/7593SNoFPLOcn1GdGybn8Cr617vVI9fAo+7twn3k++V1Ovq5uXel30O8F9AZMIOfoSQb0+Gu5ayHOOiIj52zBBJ9F4dH/AUhemel1jIfHHQfgQIP00/fTT9EdFf0Dc9T5qjCYCj56nw0Hij5FftsY6Eo3mugSd9D5fu+wuXHWPNQQudT1QjVr1Ms1unxq6VuWGP7henYx1Zx5jehsZ600fS+C4W7oaFuIbFy7UJhpw7rwu6pE4R4drvK66CFsXHOucazy9G54YRL0viem5go5ufJCJrrfS0EG9T/Sa6aduHKHXRwFMddpH7auClJ7rvadePfWCBNcfp9pGZiPPNxyDjUI15F3DN6Fr1CcaWWqQBRt40g/NCTYUg9uTmcFB+uXdNRKJc+9DgFvXsneT34Snhg41hP6Y/XP3eyPxvtC3/MH91X5p//z1F8mwl+z58bWu4RxopLrlAufDXZulEJX4mTkv87ypJ9BvO3O9WkbzVOO3EzYtuP9+6J2CqZ8fHKZXYz+/fsI9dhfMJ7Z7efSdTeK1Cb4vg/P1mtS2f5m1srZzkuszUuNxYnvqqdOyl0f+PL2ezM9IuvfGvy6J3zn63LhAtW++C0X+tS7UOUdExPyN/Rod3aVMPR2+wSjVoNXQJNewzQgBMh1SEj81hEzXz+gaCT9f3/Kn5ycaM7pgXQ1bNXA1X2HD9bBUX0t++1qHoJNs4F5Ih5Dk/lfX6FnQdTbJu4AV2ZU5HW9Yj+pU76dlHqOOu/r49uR6AxfDB3uh/LSWrr4BdUMAJzyYej8sTA4nS7w/dB7cBf+J10RDFt28S6e+n5catqZz7IavqXcmMT1b0PHTNfzI1STUN+IusCTeI8Gg416jRINX23MXSbsAVuHeb1qXu0Ne4n3XkEHHNWbdkJgh7i5T+ubYXSOQaLhlNgpdAz11EbZ6qtTYcteDJRrFUo9dA0zXEGQ02GtsM9Dw9tOCy+sLCn83LNd4TOxbYzWmXY+TwoWOTced2H6NoJBoZGoYkQKZ6vyF63UJOunQqG/+Ew3e4LzM5XQtiFu/AmAiYLvHunudGryJMOYCU+DaEtWpXuvx04L77y68Tw2Nco3tSX9wx+OHIwa3r+fui5/SdenjKeRr459nCzp6XNv+hQWd2s5Jrs+I5ge3n75xwYqB328r8Xtd59O9vrpZgYJx4rWo8b5SYE78nnKBKuPGE4U454iImL+xBx1dsOu+edd1NBrSoG+aT+x0QUF/FNQYFVmDzrzXkkEm0QDVHyU1LN31LQpPGpaiay5Sd3XTzQTc+l2I0PMD6W/qswWd4M0INN9dp5NA69S60/ufUL1D/m5tvkdJ61ePgLan7eoPsr+bWragI12PQGIdamTrj6bW7XqqEmQ20FuyuvZF51/nz5E4zz7Uuhs0JEJJel4iPKpx6W9AoYZIcF16HhxyGESvhb6t1eura258TXBdwaCjeWpUuzo1ehPhWUHCvWYi8X7W+hSI/LoaQveNdqIh575xVqNWw/omPXJDo9Bfb6B9vbbmY3c8wbtF6bE7xiV9bmgwBw028Py04PLuOpjtk92+uH1SuErsY3AdcauGavpb98T29NlxPVeJecH9deFjwyjXKHXLHl6TaNS+7xqgfl21BR23ztTd29TADc5zj/1+yMTrojCl9bttJ9636W0fWpV8nwW2rXVoXVqPn5Z5vnU7bDXs3ToS51iBWo13zcvcT/da6JqT1PEU6rXxQUJmvi+D82vbv8xab65zIrN9RjQvc//cjQwS61LYcUE08Vr7eW7/EmFGywRfl/T0lcmbEgTfQ4U454iImL+xBx2pC/nd7Xw9iQa9/hip8Vhb0NFzNVZq1KuRuW9++voIXePhe44cCh0nd6fviJUz6GSii+K17kQj2y/rtl95JrVAgsQy+mPoG7lqEKX3L7FtBS41nrVNbTvsGF3vhRre/tqjRAPfNep1bK0o6HjVYxO8sUPmvMrhfxc6r7HV66b9bOiAk2nlRz+s8b9DCq379nzoT0LnFdxEuHD7FggZjaa2nfpfOvWxPq93k35tEua7f7Wdk0J+Rpr6OUdExKR5B50oauiQG6KUcee0qGpMdK56d33MxIdrfFsbp277436ftZHr5qeGz0VV+6xv2/M9J4iIiIiIWLsNGnQQERERERELIUEHERERERFbnAQdRERERERscRJ0EBERERGxxUnQQURERETEFidBBxERERERW5wEHUREREREbHESdBARERERscVJ0EFERERExBYnQQcREREREVucBB1ERERERGxxEnQQEREREbHFSdBBRERERMQWJ0EHERERERFbnAQdRERERERscRJ0EBERERGxxUnQQURERETEFidBBxERERERW5wEHUREREREbHHeNHPmTENERERERGxJ3rR06VJDRERERERsSd60detWQ0REREREbEneVFJSYoiIiIiIiC3Jm44fP26IiIiIiIgtyZsuXrxoiIiIiIiILUmCDiIiIiIitjgJOoiIiIiI2OIk6CAiIiIiYouToIOIiIiIiC1Ogg4iIiIiIrY4CTqIiIiIiNjiJOggIiIiImKLk6CDiIiIiIgtToIOIiIiIiK2OAk6iIiIiIjY4iToICIiIiJii5Ogg4iN4qpVq+yNN95Iq+dhyyEiIiLGIUEHERvcRx55xG666aYb/MMf/mBHjhwJrcGLdvz4cauoqAidh9hUPXbsmJ0/fz50HiJiY0rQQcQG1Yecu+66K92Lo5967sNOZk2mp06dsqNHj9ZQjalz587Zvn377PDhw265CRMm2IIFC26ob47u2rXLPvjgg0YLgjqPH3/8sQtXYfNbqgqSO3bscO+lsPkYTb1v9P4pKiqyb775xr766ivOKSIW3LyDztSpU61jx451UjVh60LElqkCjQ85YfNfeuklN7+2YWyff/65vfbaa9azZ8+0b7/9tu3evduGDx9uEydOTC83a9Ys91jhZ9q0aS4kBdeVj4sXL7YNGzaEzmsIT548aR9++KELO2HzG8I9e/bYO++840Jk2PyW6vbt2613795WXFwcOr+1me97Xe8bvX/0PlJ4/PTTT23t2rWhyyIiNpZ5Bx0Fl7oMqdCyqgmbh4gt0y5duuQMMjt37nTztVzYfK8CjAybFzQYdOJsuAfX2xiqsTlq1KhG/Ua8tQYdrGm+7/Vg0NHzjRs3uh7JOL5oQETM13oFnbDpuYxSU1ZW5v7A9+/f331Lq282NX3btm3uG93y8vIbahpKbUvb1LbD5sdpYx2fvrlcsmRJ6Lx8zLY+P/3s2bM2efJk16DNXCaollVN2DxsvvqgEzbPm6vHx5sr6ASHq/lGmp53797dOnXqZG+99ZZt3rzZzdfnrF+/fta+fXv3c+/evel1fPHFF9anT58a29FwHDXW9NnUDRRGjBhhp0+frrEebSf4DbjmaT0dOnSwjz76yH2z7bevXiatT/N0bubPn28XLlxI18ozZ87YkCFDanwbnrl/CkCzZ89269DvVf3O9A1Kfak0btw4N13zfa32O3Non/bLH1Mw6GifVq5c6Y4t81ypRselYUq9evW6IRhp++PHj7fOnTs7v/76a7e/+ozruPQ7XeufO3euffbZZ65e+zB27Fi3PZ2bYcOGuaGJWl/Ya5PtddTvz5EjR7pjD25b21u3bl3o8WQO2QuuW9vctGlTjeU0MkHnNbh+zY/y2ubaj1yvjT8Hfr8GDBhgJSUl6eX0eujc6ri7du3qXju/bS03cOBAt1/arkK05mm9/ryrRscV9l7PrPfvda1D21GttqvXTL/DfdA5ceKE20/1mOk5ImIhbFJBR78gf/e739mYMWPcL0cNSXn00UfdL1r98WmqQUdj6PVHoD7DTBrr+AoRdNTwJOi0TtXga+geHU3330AHH2f2UBw6dMg1FNVQ04XSy5cvT3/jrDq9//QZDvsGOrherUfD5nRdh56rsde3b1/3e0CNc21z4cKFbhv6PaaGoEKLGsRqhM+YMcPNU72G4Pn1eDO/GZeZ+7ds2TJ7//333RdDChaa74cGq4GthqmfpwbyoEGDXKM1eBxS++XnBc+X9kmPDx486Bq0uubCL6caNfJ1jAoHwYvOteyUKVNcuNOy+n2mc7xixQq3L2qMa/v79+9350zHo+W07mDN4MGDXQNc68s89lyvo86Blte2/HLadvA1U42OR+dPNcHj1n7pNdFrquXUK6H9VBjRcgoAM2fOdK+lf/00Peprm2s/cr02mpf5mirc6LGW0+fHnw/tu8K9jkWvj45N29E8hTUdj2r8ede5O3DggHuu7Qb3Q6FU++ffz9pv7b+OQ+vX6xLcbrdu3dLvW712CuCq9ceEiNjYNqmgoz9SPXr0cL8g9VyNZP9Nkw8C+kWtb6TWr1/vfrn6Wv1CV2NZv2z1R0PT9It4y5Yt6WX0uLS01D32fyD008+X2rZ+meuXs34Gg472R9/GaZ7WrWn61kp/+PSNtAKaX78aCNpP7U/mNryarvna7zVr1tQIOn5bWofWpWn6plfLaZt6rp/6I6Nl9Vx/YKT2QceqffTH4c+p/jAFg4nfT23Lr0eGHas3uF59oxtcnze4HX/etU7trx774/Y9dnqsGj3W66rXV+vXc//aSv+tKzYP/TU6v/nNb0Ln+2t05syZEzrfq8aXvskO6htjwYZZ8LE+C74Bq+d6z+rLE/8NfDBQBOvCDJuv9SjY6OJrNai1Hr2/9S22/xz7xqR+1+jzq2+91Qugz74+k/oMa3pwvZn7LYPb1/KffPKJCzt+vm8Ua390bU/YPN9gDh5HcF7YdrUtPVeDXw1cPQ7W+OW8Yd/ia3varh7rd4ca2lKNb52D4DnyNeqlUK++1pe5z7leR40CUGDyv1f0t0Dr1/U3eo30O02/X1Srdetx8Lj1PgyuW/unUKHwlnl+gvsd9bXNtR+5XpvMeQomWo9+Zr4e/v2h85T5fpRaj45R5yjzvMvgtvQ6KOiEvZ8zz1XwdfDr0rnT30f/HBGxsW1SQUe/PNWjo6ECvmHuVdi488477YUXXnDDMnQnJ32Dpnlbt251dfr2SN9OBXuB2rRp436h64/JM88848KIatSQVi9M8A+A1Lq1Lt0xpl27dvaP//iPbj2qb9u2rftFrguc77//ftfw1h8uTfvZz35mr7/+umucL1q0yB5++GG3nP6gqy5zO3qu6VLbuueee+zll19207Ut7be+ldMQEO2P1qlzoqEUGrKidWjoh+p8iNC3aT4Q3Hzzze5bV61b503LqiYYQLROrVvb0La0TW0727GqRj9/+ctfunOvdf3whz9Mzwsa3I5/7I9Z+6x6bfP5559329N8Ladj1D77fdEfzQcffNC9tvo22L+2mdvDpqu/65re375nTz/1XNNrG7Ym1fiS2eb5hlnwcWbDVNMzw5J+B6gxGKwLMzhfDTs1aPV5Gzp0qHtv6r2s7WU2OoMNQz1XEFHjT59N/W5QEMz8XZe53zK4fb/OzGPR50efjczGa3CfMo8zOC+4XQUEHZe+eNIQJjXi9btH8zKPMajmqycjc98Uvvzy+p2idfm7yfnjCe5zcF8y91mPM9fvX0eFDA2VVQ+H9l29W74hrt/NavTr3CsI+N8jwW3p74O257flt6dpma9L5n5HeW1ltv3I9dpkztM+aF+0T2Gvh19+3rx5N8zzy2sdwf3PrPXLZp5rqZDjz4uvC+6Tn6aQo3PinyMiNrZNKujoj4J+Md9+++2uca4Gr/9mTmHjlVdecX9M9FwN41dffdU1hvUHwzf+tQ59y6TAo1o1mFUrn3rqqXSviRr3Pih5te6nn346PSZb9Rrj74NOsNdDfxDVsNBjDSd47LHH3HJ6rh4M/8crc55XfwT1bbbWq+cKazoO7Zt6sNSI8tvSdrVf2j8dpxoJ+gZQ37QpBOhcqNGghqOCl54rdAX3Vd/G6rEPHf5YtW5N90FJ2852rPqmUPvoQ5POtRoTWp+eB/XbCT7WsalBol4pTde5efzxx90ffs1X75CCpo5D87SMpvtj0fbUSPI9Pdg81Hsz2//RiXqLaTWogo2qzHm+YRZ8nNkw1XQ13sMan8G6MIPz1Vvx7rvvpn8XBRt4uXp09JnVZ0sNb+2DltdnWd+a++1IfUuv9Wl4kJ8W3L5f5+rVq9PzvZoXR4+O6v3QKC0XnBes8evxar5+1+hueJnzpB9OpiCg/dB58Mej9frldI61Hp3jzH3W47DXUc91fn0viral4V7q2dA0zdMyOv+6Fsb3GAWPTQ34zHXrd5IMLqfpwf2O+trm2o9cr03mPH8e1ZuY+XpovfobqGPR+zHztdL5UMBS73jmeZfBbWme/pYG672Z50rnRedHx+6XydxvRMTGtsndjEDqj4bGY6vhq4a8QoOCQnBolxrACgoaCpEZJPw8Latf0goHaqxPnz7dNbrVUNa61avja6Smq+HtG9mq90PX9MtcQ7zUK/Tb3/7W9ZhoXVouM8zouf7AqufijjvusFtuueWGoKOg5etl8Pg0Xfvr5wXXrz8i/nogBRN9Y6nx7AomOiYFAh1/cN3BUKafmq91aZ3+WIPLZTtWNViffPLJGsfi1+efh033j4PnU9ODx6X5f/d3f2c/+clP0kFK6o+nvkHUfuiPsr9wF5ufCvf6pl3hRj/VUNJ0H4JyhR01mGS2eb4xFXysz4oay77nQJ/v4HUTej9+++23oddHZKr5fgiOGq9qZOric/2u0mdFn0VtTw1QNXB1rFpWQ0P1/leDUY1ZNWo1bFPz9FyhSI1Rv53g9ODwr8z90xcS+tzrGPRcwWLp0qXus6t5Cjs6Lu2frhvxjV2tQ0O71BhWiNG37X6e9t835NUY1u9OrUPLaZ36/aJ5mQ3roFqvvkDSev0QLv1u0pdHmqdtaxiYH8IWvEZHF9xrGal6rUePM4892+uohrsa8H5InGrVE6X3WfA1U42+WPJBKnjceqzXS/ul5fTFkfZTr0VwOc3z+12X1zbXfuR6bXQOdGz+nOoY9TdGr4+2r5sEaFi31ql9Vw+jzo96+7U9/37UOdJ+KcgG99/vnwy+1/37Wcel7Wr7Op/6TPnXwZ8r/1znSc/9ELqwQI6I2Fg2qaCjnhD/S1LqF6t6DBQK1BgOCzoKQc8++6z7g+HrNCRL29IvWv2C1y99/fHSN6X6g60/oOqZ8N/IejVfjXv/RyjYMNcf6hdffNH94dO8YHgINtgVNLS9SZMmuUZGcJ7fjlT4Cl6PFDw+NTCC3f3aHwUMnRsdk9avb9J0HDoGNbI0rEvHpuV1bvy+ybCgo3Vpnf5YpbapbWc7VvVwqVcteK79+vzzsOn+cfB8anpm0NEQOf2x1375HjGvjlMBSMtk/mHG5m9tYUeNL5ltnm8IBx+rIacGv3oE9aWGPmsKA7qgXJ8h/VQDOawxnanec3rvquGmz4E+E+rt1e8R9XzoPe6DiRp2Wlbr13Rty79n1fBVo1Qq7PlAENyW9lMX4utLDD8tc/98Q1jr0LrUGPWfKzV+dXcw7Zv24b333ks3mPV5V8NXdZqnsOTnBRvyfh3+GPX7RdtQw1fH4mv8/gTVZ1XnROt/8803XcNan2c1rrV+NbZ1jGqs6/VRo1nr07741yUYBjKPPdfrqC9CVKvtarr2Q/ujeRpuqOP2NT4YBo9bz9Wo1+9U/xr5u6cFl9N+ZAaFKK9trv3I9droHCjY6G+Gjk3753vNtH0FDO2btq3XTH9ftE7N1/tCr51q9L7U0D7tR+b+e/Xcv9e1jP4ua7v+uNS75QOXzo3fX40w0N8PnSetR+8Vvfb6GVw/ImJj2qSCjr7p0x9V/ZHVc30rpjCjBm4wCGieGsaap0aH/iCoq16/eP0QLAUNLadvtNSIUmNHIUHfPql3QN+++T8EXv3y1vY1fE7P1dD3PRj6I61rdrR9bUN/ONSI0XLBBrv+MKgH4rvvvnPz9EdC2/ONEK/2Q6HKhwlt01/Loz+0OjZ/4b3+aKkXx//RVCPrtttucyFOx6Dj//Wvf53ehs6N3ze/vH+un5rvj1Xr1nRtS9c/6Q5G2Y5V29Ifs9GjR7vH/vXR+vy2vH47wce1BR2/jeA1OgpzamRputQfXL/P2LKM0rNTV/Vlg953eu/4aXqsaZoXXLY29dnW7xD/XI+Dz71qRGrdWl6q8ZfZmNTvOC0XnBZU346rke5/F2ZT68hcRsfnt6/5Cl7BYFKX4/frCJtXmzo3fpu51DK+we33O2y5THMdh9YR9tpo2cz3Q5j5vkdkba+tzLYf2bbrw57m69iCdTpv/vWV2bYdZb+8YecvW72mafnM6QpB/s55mfMQERvLJhV01KhWo1YX9isc/PSnP01316sxHBZ09FwNZoULNfZ1fY+GAvg//lqnv3ObnmtdasRnayyrgfHAAw+4IWf6qZsKaNtqdGsbGsaleQoJWq/WL/XNlW5coPChHiXtu/ZFYUYX0GcOk9Mvf32zduutt7qhPE888YQLMzoerU9/2BRmtC3N89+SSa1L19f4HimFE13Ur9Cn5z40+OXDgo4ea51at7ahbWmb2nauY9W3jgpEOjb1rmh4nl9f0OB2/GMdW21BR9O1HYVVBR4FVf/aSu2L9s9vB1uWCjs/+MEP0sPNmptq8Ol3mBp56sXQFy76lr6ux6PfDxrK5Ru3YctkU8FG+6DfZep91RcVTfnLAZ2zsJ4F/N7MXq2gwaATNr8Q6u+E3oO+Vw4RsVA2yWt09Iddjfa6/oFXA1mGzauL2m62Pxqanu1bvuA3YFomyh+eXPscdR31Ndsx5TpWzavr61MfdW7DvqHFlmdzDTleDW3S9YC6I5t++qFOdVVfyigo+dvLR1WfWV0Xo8ax1ONsn+OmoD7XGnrG9XfZ1XVgmdf7eHXedP6ayu9Hvdc0OoPXExGbgk0y6CAiIiIiItbHegUdf81IFLUsQQcRERERERvDvIOOrnlRcKmL/joZRGzZ6roqRERExEKad9BBRERERERsqhJ0EBERERGxxUnQQURERETEFidBBxERERERW5wEHUREREREbHESdBARERERscVJ0EFERERExBYnQQcREREREVuceQcd/mEoIiIiIiI2VfMOOmFBJoph60JERERERIzTJhV0iouLbdSoUXby5MnQ+c3VsrIye+mll9zPPXv22KRJk+zs2bOhy+ar1jd58mTbuXNn6Py6uG3bNnvttdesvLw8dH5Tc8yYMc44zwEiIiIiNm8bLejMmjXLNm/eHLourxrYjz32mAsEYfObi6dPn7bu3bvbqlWr3PNg0Dlw4IB9/fXXDRJ0dI6bUtDR8es86HyEzY/LYNCJ6xxg/b1w4QIiIiJiwWyUoKPG57Fjx6xv376h6/JmBp2KigpbuXKlLVmyxEpLS23NmjVumh5v2bLF9u/fbwsXLrQdO3a4g/HrOX78uKtR7alTp9w0NYI3bNjgeo2WL19uJ06ccNMPHjxoixcvtvXr19v58+fT6wiaa31+PX5ftW+LFi2yBx54wIYMGeJ6cIJBR8urzgcd/Vy3bp3bB3/cfpm9e/fa2rVr3TLaN50fHa9+hu2rzom27/dNj/35y9ZL5vdb29e50DQfdPbt2xd6bnQOfI3fZ79Nf34VanX8Og86H9qOr5d6vYqKitzx6Pj9+ZBh+yT9uVKNXns/3QcdPY56Dvw2Mt9bfj7mZ/CXi94zmZ47dw4RERGxUYwl6Lzzzjs1ngcNhhw9D1uXNxh01JvQtm1be+WVV+yrr76ye+65x373u9+5eWqc3nzzzda5c2c3784777S5c+e6dWzdutUtpyFwH3zwgT366KNWUlKSXp/W8+6777oGuRrgDz/8sBvupH0bMGBAjQZ3betTGNA+azntl/ZdweSjjz6y2267zW1v2bJlbp4POj5EqF6BRsvo/I0bN85tZ/v27W4ZHdPTTz/tjk8NcK2zTZs2Nn36dHviiSfc9GC4k71793bnJnisI0eOtLfeesuef/75dCjzHjlyxG1D2x8/frzdddddrhfGb/+FF15w+/XII4+49ahGx67tDx06tMY+Z57fGTNmuOc6D9r3zKA1bdo0d778TS369+/vzn22fQqeK9Xef//97li1rmDQiXIO/Lyw91ZwH7Fu+oCjXyx6Lc+cOePeu4iIiIiFsN5BRw1aNWLDwk5myJFh6/IGg44at88884yr1zwFjj/84Q9unhqyr7/+ejqUqJH79ttvu4aVws/s2bPddDW6hg8f7gKKGrcdOnRw39xrntarBvWmTZvcczWwFUbUA6Pnsrb1hQUdPdc8rcs3xDUvLOioka8GuD8OXbujdWsZNcL9sWfuu4a/aVntn557g4384PLa7uOPP+56voLLa/t9+vRJByYFvw8//PCG7Wudr776qhuCpt4PnTNfo23q/Gdu09fpuDXPT/OqbubMme6xesy0Dr2Psu2TAkqw50fLax3+sfTrre0c5Hpv6Tnmp14zhRy9L9Xrp9dTry0iIiJiIYylRycs7ISFHBm2Lq8a2D7o6Nt835DNnKeGbHCeb/Rqng8bfp5vbKuBHgwmavD+4z/+o91xxx3229/+1vUc/OQnP3GNYF9bl/UFl1UjO0rQUThTz5S2L7U/OkcKEn4Zv905c+bYrbfe6gKIHiul+nneYCM/274Fl9f2fUAIGtxHPffHrOcKGrrGSOvTPv/N3/yNW0fmNjPr/DSvQsvdd99tTz31lE2cODHd45Ntn9SI1lA2BRRtV+fNvwe0vK+Jcg5yvbf8NKyben00NE0hR+ceAAAAoNDEdo1OMOxkCzkybF3eYINT3+T36NEj/c1+cJ4assGGqhq5eq5tPvvss+4bej9P69F2NS/Y8FXPjYZgKfBond5gL0ld1qda35BWQy9K0FHvjXqI/Lal1qvt+WX8dqVCxq5du9x5feONN3L26GTbt+Dy2n5YqAjuo54HA4uGCHbq1CkdTLRNrSNzm5l1flpQNYzVO6VzoN41Je9s+6Tw9+KLL7ohh3ruX3P/2NdEOQe53lt6jnXX9+ao10+vIwAAAEChifVmBAo7avCoERwWcmTYurzBBqca9HrsLzqfN2+e3XfffW6eGrK+kSt9o1fbHjx4sGs467GCQbdu3dwwr8yGr3pENLRJw6f8suox8DcbkLnWpwadrvPQvmhZBSZd66H1a1tRgo4u2td1I0ePHnXL7d69213EH1xG09W4VxDw50JBSD07Pmx4ozTyg8tr+xqSpmFhOr7Ro0enh84Ft691+sCi3hBdg6OQojpN1/nP3GZmnZ8mVaf998PKDh8+7HpqFHqy7ZOudWrXrp1bl14HDW/LN+jkem/pOdZdvR/0uui8axgoAAAAQKGJNehIXZj+8ccfh86TYevyqhHqg44aubrY/ac//akbVqbelwcffNDNU0M2LOjosea3b9/efv3rX9vtt9/uhkIpvIQ1xNWro+1pOam7hKmx5ufnWp/mqWfgZz/7mbtwXzcp0AXyfv3ad82bMmWKW0dY0NG2Pv/8c7ecjlE3RlBgCi6jdelcfPvtt/bLX/7SDdvST4Uyv4/eugYdbV/H/POf/9wdn44zcx+1XDCw6GYEujmBhtnpAn4FFt2YIHObUgFGy6pXTI1fP10q5CgY6rh1wwIFKB8mw/ZJwUePNWRNww117VTXrl3d8nUNOrneW8F9xOj6YWt6nfS6AwAAABSa2INObYatK5tqxHp1i2P1wPjGd236urB5map3Rg21sHnebOtTXbb/E6Pl1agOmxc01zqCal3qxYmyzroYdftBtXzUY8v1Ouh4ws59tn3StLDl66p/PWVd31tYU70P9Jr4oHPo0KHUrxcAAACAwtFkg46+XVcvgm7rrNsJ6/+x6GfYsoh1kfdWvBJ0AAAAoCmSd9Dx//+kLqombF3Z1BAxXZuh2zvrn0vG3ZOBrVfeW/EZDDq6EQFBBwAAAJoCeQcdRERJ0AEAAICmCEEHEeslQQcAAACaIgQdRKyXBB0AAABoihB0ELFeEnQAAACgKULQQcR6SdABAACApghBBxHrZXMKOrt373b/HFb/MwkAAABaNgQdRKyXBB0AAABoihB0ELFexhV0FEJ++MMf2k033WS//OUv02Fk+fLl9txzz7n/xZU579KlS26epkst69EyWjZY44POwIED3XRtT9NqI7gu2bNnz9Sc8O3kmg4AAACNA0EHEetlHEHHhwIfVBQkFGAUZDRNYWHMmDHpeT5oZC7ng4sPQH59qtWyPkwF1+Xrs+HX5Wu0jttvvz3ndrJNBwAAgMaDoIOI9TKOoKNAEOz1UIjwQ8yyzSstLa0RJoKBJFgfJBhShGpVkyvoZKJ1at1aR67thE0HAACAxoOgg4j1Mq6g44eFeX3vTGYY8SFi7969NXqBhHpNFHQ0LWy4WGYAiRp0MvcvuG9h28k2HQAAABoPgg4i1su4gk62wJEZGvzzfHt06hp0tKy257ej51qH1hV1OwAAAND4EHQQsV42xDU6Cis+3GiaelH8PPXa+Otd9NMHFc33PS1h69NymzdvrnfQ0bpq245CWNh0AAAAaDwIOohYL+MIOkLBQQEiODRMKCwonEjNCwYT34vjh5T5YCGC6/OhSdPqGnSEgorfxrBhw1yN31bYdnJNBwAAgMaBoIOI9TKuoJONqGEEAAAAIAhBBxHrZUsIOtqG77HJlNtCAwAANE8IOohYLxs66AAAAADkA0EHEeslQQcAAACaIgQdRKyXBB0AAABoihB0ELFeEnQAAACgKULQQcR6SdABAACApghBBxHrJUEHAAAAmiIEHczL06dPW/fu3W3VqlWh84OeOnXKBg8ebL/97W9typQpoctE8cMPP6xXPTaMBB0AAABoihB0MC/1X95feuklW7JkSej8oHPnzrUnnnjCdu3a5erCloli79693X+o1+Pi4mIbNWqUnTx58oblsHEl6AAAAEBTpEkEnbNnz7oGkhpMYfPxe9WgPHr0qDtnYfOjqHNdUVEROi+qdQk6CicKKWHz6mIw6Gzbts0ee+wxKysru2E5bFyDQefEiRMEHQAAAGgS5B10BgwYYLfeeusN6j+Mhy2fy82bN1ubNm1c49k35PVTjaY//elPtnbt2tC6hlD74HsdNm3a5BrzCgaZyzWmwXNy+PBhu++++9w5C1s2im+++aYtWLAgdF4u161bZ/fee6/9p//0n9zrpcc+6PjhaT/84Q+dQ4YMcWFMw81uvvlm+5u/+Rv7wx/+4Hp1FE66detm//k//+cay4YNh9NQNa1Dj33Q0bTbb7/d/ut//a92xx13RBo+hw1nZtDRexQAAACg0NS7RycYUsLmRzG4DjWSnnrqKfdT8zQ0SY2ozJqGUsOhpB5ru01haFTwnMg4g44ap1F60o4cOWKPPvqoTZs2zZ0XhcCf//znLuiofvjw4S686HypsauAqCFrqg326CjQvPXWW/bZZ5+59WgImo5H69Hrn9lLFKxtij06O3futHnz5mVV88PqWpo+6Oj1Ly0tTf16AQAAACgcDRJ0Dhw4YM8++6z7Jv/VV1+1gwcPuunqGXnjjTfspz/9qT3++OO2ffv2GuvYsGGD3X333fYXf/EXrlGt9fTq1cstp56idu3a2dNPP+2+yVfvQebwLT3XdK3/F7/4hX377bfpb5vHjh3repx++ctf2tdff+2mq5Hctm1b1/B/+eWXrV+/fukeiQkTJrjtavvqrdDz9957L739jz/+2M6dO5fepqZpnvYxs1cruO/qDdF2tA86P//wD/9gixcvdsv5/dR07b+max+C50QN/N///vfWtWtX+9u//Vu755570ucx2/nN3EddL6Ogc+zYMXvkkUci9YgsW7bM1frgFwwlWo/mrV+/Pr18MKAEH3t1/lWn10DnX8s0x6Ajt27dap9++ukNanrY8i1RvXf1PtNrqN5HAAAAgEITe9DRzxdeeMHmzJnjGrPffPONtW/f3jWQFRr0Tb6maziaGtxqqGbr0dFzTdd8Nczvv/9+t7yGOHXs2NFmzZpVY18UKDRdDa59+/a5x2p0qWdBDWj1NCgMKISp4a5t3HnnnTZjxgzXUNM6gj06wf3SNO2v6lX35JNPumFY2gdtR/ukQKfeicxhYXr+0EMPuV4R7YNqFTy0zZUrV7rheQpT2s/XXnvNrUshT+Fh//79Nc6J32edV9WPHj3a3n77bRe6sp3fKPtYmwofOofB19mHEm1DYewv//Iva6iQq21mBh2de92BTcfXv39/+93vftesg47cuHFjjZCj52HLtVT1ntN7UNd+6T2uXh29hxERERELZexBR99iq4Hrv/lX0Hj++eddw++ZZ55J9+6oQaTG95o1ayIHHU3321Eo6NGjh3vsVfBQg3vo0KG2Z88e1/jSdC3nh1HJiRMnuqChbWQOA8sVdNTzoOnB/dK6Z86cma4Pu/5Fz31t5jLBbWhduvZJIVHqeBXeguckc5/9utXgz3Z+M48/bB9rU+FEISSsR0fb1vU32XowgmFF9Xo/BHu9fIAJrjOstikHHakeLYWcYM9Wa1GfNd+r44M6AAAAQCGJPehkPlcPiIaFaXiUb6xrur79Ve+FGrzBmmCjXs99oFDDPBh0MsODV/M1T0PF1FOi55kNewUT9YJkhgZZ16CjabWFiMx9DS4T3Iamf/DBB+mgI3UHq+A5ydxnv+7gMpoePL+Z+5T5PIq6lkY3H1i0aJF7rp4mDZtTKFHjVtfd6JwqYKnR+91337neKi0bDCsarqZhdbp+Rc91DYvWo2VU16dPH3e9jx6rZ+CVV17JGnQUrvzxNhVXr14dOr01GAw7BB0AAAAoNLEHHTVk//jHP6aH7qhH4bnnnnPfvKuHQdfNaHpRUZG75kQN5uA6gg32YKBQw1xDsdQjoAaVrnNRz4zfD6nhXCNGjEg3khWw1Mug62HUEFcDTHbq1MkN59I26ht0tA+6CF/r9cPSMkOEDyP+eTBoBLcRXJeOQY1FPQ6ek8x99uv2PThh51frVUhQIzRzH6PejECqV+eWW26xn/3sZ643RT1IvvdFr6+ud9K8f/zHf3TD0rQPmhcMOlJhSXdh++u//mt74IEH3LLqhdM8vV633XabW4+uqdIww7Cgo/Ol7f3kJz9x++XXjYXVhx2CDgAAABSa2IOOXLFihbuYXnfl0vUXW7ZscdM1tEyNdE0PXoQfXIfUNT4PP/ywa6T7QKGG+Q9+8AO33r/7u79zIUaNdr9NqefqxVEjWcsoDCkoaJ26bbEu8td09Zr4AJEZdLSdH/3oR+7mA8H9yhZ0fKDSenWsv/rVr9IhIrjOKEFH61IvjPZT6rGmBc+JejLCgo4eZzu/2faxLjcj8KoR64evhangpP0Nmxc013r8vNoCWNTlsHH1IR0AAACgkNQ76GRTjR1dYB82T9NzNU41Tw3m4DQ1zNWroUZ7tvV6VasgE3V6plpGjeiweZn6IKV1a990fVJ977al3hkZnBZ2TrKZ7fyqPtd5R4xLgg4AAAAUmgYLOnHrg06U3oLGVLdw1rUiGhqnoXUaXhUlTCG2ZAk6AAAAUGiaTdBRD4fu4NYUeyQUbHSNSlPdP8TGlqADAAAAhabZBB1EbD4SdAAAAKDQEHQQMXYJOgAAAFBoCDoYyfbt22OMhp3jliRBBwAAAAoNQQcRY5egAwAAAIWGoIOIsUvQAQAAgEJD0EHE2CXoAAAAQKEh6CBi7BJ0AAAAoNAQdBAxdgk6AAAAUGgIOogYuwQdAAAAKDQEHUSMXYIOAAAAFBqCDiLGLkEHAAAACg1BBxFjtzkEnevXr9uZM2fsypUrqSkAAADQkiDoIGLsNoegc+nSJXvuueds+fLlqSkAAADQkiDoIGLsEnQAAACg0BB0EDF24wg6Glq2YsUKu+OOO+yWW26xqVOnumnr16+3zp072/PPP28/+MEPbOjQoXbt2jVXc/ToUXvxxRfd8h06dLATJ0646adOnbI33njDTdd8LeeDTp8+fezWW291rlu3zi0fhpYfNGiQ3X777fZP//RPtmrVKjdd2x43bpyrv+uuu9w+az+zTQcAAIDGgaCDiLEbR9DZvXu3vfTSS1ZRUWEXLlywNm3a2Pbt210PzEMPPWSnT5+2y5cvW5cuXWzBggUuiLzyyiu2ZMkSFyjmz59vr732mtufnj17uueavnDhQlej63MUdD7//HOrrq52QaRTp05Zr9lR/SeffOKWPXz4sAtMWoe23atXL7cvClDPPPOMHTx4MOt0AAAAaBwIOogYu3EEnfHjx7tAsnjxYqceT58+3QUdBRQFG/Hdd99Z3759raioyPXiaPtCIeTll1+2nTt32gsvvJDu3VFQOXfunFsuOHRNwapjx47p9WaikHTo0CH76quvrHv37nbvvfdaeXm527b2waNQpt6cbNMBAACgcSDoIGLsxhF0xowZ4wKFDzqypKTkhqCj5+qxyQwqCjPqBdq0aZNbXqEkiJarS9DRcurx0T4oVD399NNundq2X0eQbNMBAACgcSDoIGLsxhF0dC2OhoepJ0SoR0YhROFBIUPbUS/Le++953p6zp49a88++6zrwRFbtmxxQ980xE29QRs3bnTTFVQGDBjghsTVJeh8+OGHNmHCBPdY63jiiSdc0NG2NaRN+6Jhalp3cXFx1ukAAADQOBB0EDF24wg6GualoHDzzTfbz3/+c3eNi8KOgskPf/hD+9WvfuXmqdfGh6ENGza46bfddpsbWrZ37143XT/1XNPvvvtuF2rq2qOj+arXzQXuuece+93vfmdlZWVu22+++ab9wz/8g5unMKRwk206AAAANA4EHUSM3TiCjkeBp7KyMvUsOYRMAUVBIjjdozARNl1oem1hY//+/Xb//fe7u6t5u3btmq7Ntu6rV6+GXoOTbToAAAA0LAQdRIzdOINOJj7oZOt5AQAAABA37dq1yxCxdRkWTuK0IYOObv+sO6oxDAwAAAByQY8OIsZuQwYdAAAAgCgQdBAxdgk6AAAAUGgIOogYuwQdAAAAKDQEHUSMXYIOAAAAFBqCDiLGLkEHAAAACg1BBxFjl6ADAAAAhYagg4ixS9ABAACAQkPQQcTYJegAAABAoSHoIGLstsSgc/78+bRlZWW2d+9eu3DhQl7Onj3bGTYviqWlpc6weVGknvrmXH/ixInUpxIAIDcEHUSM3Zbeo3Pq1Ck7fPhw6lndmT9/vjNfTp8+7cwX6qlvzvUKOwAAUSDoIGLsEnRyQ9Chnvr86wk6ABAVgg4ixi5BJzcEHeqpz7+eoAMAUSHoIGLsEnRyQ9Chnvr86wk6ABAVgg4ixi5BJzcEHeqpz7+eoAMAUWnWQefMmTN2/Phx90svbD4iFkaCTm4IOtRTn389QQcAopJ30NEvmoULF9rjjz9ud955p3Xs2NH27dsXumycqoEh9XjZsmXWqVOn9HPvtm3b7M0333S3oAxOR8TGkaCTG4IO9dTnX0/QAYCo5B10Nm/ebO3bt3d/7PV8xYoV9vrrr1t5efkNy8bpuHHjnHqcLejo/1w09H4gYnYJOrkh6FBPff71BB0AiEreQWflypWu16SiosI91881a9a4gDFjxgx777337Pnnn7ff/OY3LpiMGTPG7rnnHjdt586drkY9Lv3797cHHnjA2rVrZ7t373bTFVSmTZtmjz76qD3xxBP27bfful9sQ4cOtd/97ndObUNBR+vr3r273X333fbuu++6BsiePXvsgw8+cL9Itdzw4cOtc+fObpnPP//czp0759Y3ffp0u++++9w6tL9a1h8fIuYvQSc3BB3qqc+/nqADAFHJO+go0PTu3dtefvllW7Rokful5ecp2Giewk9JSYk99dRT6f8Crp/vv/++CxsKI+PHj3fTN23a5HqIjh49akuWLHEhSttQGHrttdds9erV6XUHe3SefPJJ16hSw6Nbt24ubG3fvt169OjhpmlZrVfr0X8z79ChgxUVFbkeKfUGHTt2zO27wpJfLyLWT4JObgg61FOffz1BBwCiUq+bEeiXjULF4MGD7aGHHnK9MJoWDCNqECh0aDk9VzhRz8uRI0dcL4sf+qYbCygcbdy40QUhhR2/nZkzZ9qoUaPc4+C6M4euab2alhl0NF3zg/syadKk9Doz14uI9ZOgkxuCDvXU519P0AGAqOQddPSH3gcMqYbNq6++6npwgqEhGC703Acd9a4opOinpquHp1+/fq5HxgcWv+558+bZxx9/7B4H112foKPpX331lZueuV5ErJ8tMeioV9hbXFxsW7ZsqTGtLn7zzTfOsHlRVK+0DJsXReqpb871amcAAEQh76Cj62YGDhxoZ8+edc/rGnTUg9OnTx935zZf37ZtW1cfXLfs27evLViwwC0XXHd9go4ClYbEaXictqFrdPx6EbF+tsSg438fydLSUndNob6gyUf9jpNh86J46NAhZ9i8KFJPfXOu15BzAIAo5B109Md+5MiR7kYCummAhq7NmTMn8tA1PdY3Oi+99JKr/8Mf/uBucKDp6tJW8Hj44YftwQcftBEjRrjt+Xrd1MDfjCDfoKP1acid9l/X+ehaI4IOYjy2xKATRL9LGLpGfb5QX796hq4BQFTqdY2O1C8c/cIKmxdV1Ws9mdPV6+MDTlBN053ZMqfXRX0r5HtztC7d/c0HLUSsnwSd3BB0qKc+/3qCDgBEpd5Bp7mqa4M0dE29PbrjWpcuXVzwCVsWEesmQSc3BB3qqc+/nqADAFFptUFHqidHt7OW9e0hQsTvJejkhqBDPfX51xN0ACAqrTroIGLDSNDJDUGHeurzryfoAEBUCDqIGLsEndwQdKinPv96gg4ARIWgg4ixS9DJDUGHeurzryfoAEBUCDqIGLsEndwQdKinPv96gg4ARIWgg4ix29SCTmVlpXXp0st+/KNb7LFHn7eKijOpOUlqm58JQYd66gtXT9ABgKgQdBAxdpta0Jk2bZZTrF+/2QYPGuYee2qbnwlBh3rq463fUHrOus/fb69M3239vyuxsrOXU3NuhKADAFEh6CBi7Da1oDNyxOjEPpW4x+qtUZBRL45H4SYYdPzjbBB0qKe+/vU+zMzfftjadehrK9s9Znva3mfz2z1lz7451A6d+f4zGoSgAwBRIeggYuw29aCjYWqZw9MUbjR0LVtvjv7JsHffvn22adOm9P/hqqszZsxwhs2L4u7du51h86JIPfVx1x/fu9OOJj4bwWnyWFmp+1ladiStanfs3GULtuy3Q0V7bWLPHna5ze12pO3dVt72Lqtqc5tZm1tt2BdTb1if3L9/f+pTCQCQG4IOIsZuc+vR0fNgj46CUHC+uHTpUlo1toqKimpMq4tz5sxxhs2L4pEjR5xh86JIPfX51B+vOOd+htVfLt5llSeP1ph26Xxi+ZI9VnrqnH2z/YjtOHDEig4esaOlh21HUbGtnDDWKt9+xq62+YULNjPaPWdD27d3j+W37/apub6U5eXlqU8lAEBuCDqIGLvN7RodPdd0oUDUt+/AG4JOEIauUd/S6i9eqUo9SnKl6roVn06Em/NXrKr6unu+qfSMLdp/yvrO223HTp6yJTvL7OyBIltddMQ+H/+tffT1Ums/a2+y/uo1Ky8rs0PfTrJ3PvrK/mOnSfZsh3ddmDnQ5XEr6/IHF2Yq2t5pZW3+ySa3e9E9n9XumXTQWTPgLbeuTBi6BgBRIeggYuw2taATdle1YKDRc03X/DvvuD/d+5MNgg71zbq+vPz7+upqu3rxgi09UGHvLS2xktOVdu7yNZux84T9/bvzbcKmI/b1mv02fdk2u7//VPvnnefYTZ3n23/otcAe6jDIBZe7O35i59r82oWTwe072dffLrPrM4Zbca8X0qGlsv0d7ueJNr+xeW2fsiVtn7APu/W1X3+ywn70+kTb0PZhu9jmV3Yt1bsjD07+LLmPGRB0ACAqBB1EjN2mFnTihqBDfXOtP3uh0s4c2G2Hjp10z6+cOmHbNm6zP++2yAUY+V/enO5s16GP/ZdO4+yd9m/YgPav22edOtjW3u1tVY821qXPELvS4c50KJFVI7pbVSKoVLe5za62ud1NW9itnZUvmGbW6U67+mEHO3e01DrN2GYvTt5i5ReuWsWla7ZjzTq3bDDkXHzzQbNz4cdI0AGAqBB0EDF2CTq5IehQH1e9hpTVhoaeyfKLV6388CE7t3mFTd+wz4p27rF5nwy2Te0fsY0dHrWVHw+wPp99Y5M6vmpH296dDh1Z7XyX2aRBZgOeM1s7L7Ezl23VsEG2ud0j9k8dP7ZuwxIBp7o66Y41ZhUn3P5sKzlmm4uPusdC+2bHDpotnGA281OzZYm6i+dSc2+EoAMAUSHoIGLsEnRyQ9ChPqxe18TUhsLKnsPH3TUyuq5mU9k5FxR2Hr9ghyoqbebOk3bkzGU7nHhs5yvcMnN2nbAPJ39ns/v3tj1t7nUhRbdy9sPNwjzV62m7PLq/XXn7WbvyzWdmX/S26uUzE6nkmp3Z8J1d/biT2eJJZmfKzY58/3k/eeSoVR0qcvviAoxHy12+6B6eLD9lZcfzv6EAQQcAokLQQcTYJejkhqDTuuoVToL4evXGKBAIPV5ferZGD821M4lAcPayzS8qt42JQCP2lV+y4cuL7JMlu+2rZbvs1kHfWZuZu63XN1vtnp5j7e87fuaGn/3k3UW2YdU6G/XlFLut4wgXcM61TQabbV2fcz/3vfYH2z7sPReIFGBs8zKzTUvs/MYVyf9xo2k+xBwtSS6XwO3/yRPJ+QovF8666eJAeSJwHT56Y0+TenVS1PX8ZULQAYCoEHRam0vfs4uD/5tdfPP/klSPNS1sWcyq/tDOmzfP7r33Xrvzzjtt3Lhxdvbs2dBl9T8junfv7tQf97BlWpoEndwQdFpPve5atvXo+XTvhn7q+hg5Z+dRe3jcNhdidAMABZ01B8/axC3H7JudJ23szO/stuHrXHD5v3aeZy9P22W9Fh5wz/+20xf2VbtXrKzN3XZ7x+E2LHBb5oNvPGZT271Qo8emquNdtm7CGKvet9WOHD1mx3Zvs7ITFTV7XQKkg4rCjPBhKEGu41dA2nEsdxCpy/kLg6ADAFEh6LQiL4x/yC4N/I928a3/WyLk3JQ08VjTNC+sBsPdu3evvfTSS1ZcXGwnTpywtm3b2tq1a29Ybvv27fbEE0/Yxo0b7fz58zfMb6kSdHJD0GmZ9cGhZwoKcvzmo9Z+1h4bta7M3cms76Ji+/tPVjl/8ObU9A0Abh+5wf5qwIr08z/vNMv+uuNo+7edptodI9dblw8n2v/RaYr9604z7LWen9iR1x6w021q3gygelBbsxFvmvV+3D2/mgg3xaPeN/uyr9mh5G2fhd//bCEnlIg9MgpsCne5yFUfBYIOAESFoNNaXPpeMuR0TYSbEN08enYiu2TJEuvdu3f6+ZgxY5zBZfTHuH///rZ8+XIXhrL1+LRECTq5Ieg0/3pdZ+JRYPA9MrpWRs/VizNx67EadzOT/6LzbPuzrslpd/WaYGPXltg9Q5e6QKNbN9/31RabtKnUhs1aa0UjB1rZ2I/NJg9OXvifCC+H2vzOrr96q53q9Hs7t2KO2fZVduWrAbZvwezkzmgo2ckys2lDrGrbyuS0K5eTP1M05PnTsd8wbC2D+m6foAMAUSHotBY1RE09OSEhx6l5WiasFm8wStA5efKk6+m577777K677rJf/vKXtnTp0hrLtFQJOrkh6DTfejXi95WdsJEr9tlL03bZ3V9stp8PX2/7T12yYWsO218PXm2/+3KL+6kw86+7zbfO3xZZn4UHrO/snTZt/krbf+ioDZqzxS5sWGa2f6td+ayXfdPhRVs0sJ/Z2P5mfR4363Z/jd4ae/spuzqiu1V3vNMujB9kR/fsSu7QhbNWefxI+lofz/Xjifdn4NqZIIU8f6K+9QQdAIhK4wadsAY2Np4aqhY2XSbmXej6z2zhwoWtztD3ai1GCTplZWX22GOP2ZYtW9zzdevWWceOHa28vLzGci1Rgk5uCDpNuz5zSJeuO1EPzcbS8/b67CL7j/2XuRCj62Z8T83ffLgm/dj78udL7dC3k+zUmfN2sfyE2ayRZgOet6r+z9q1D/6UDDCd73I9NDVCjQ85fZ9wPTa2a11yR65ctutl+2/4h5/a38wbHrieHX99TQYNff5qo771BB0AiApBpzVJ0Ak19L1ai1GCzrFjx6x9+/auQaznCj66rkc/g8u1RFti0Dl48GBaXaOl4KrXNh+nT5/uDJsXRV37JcPmRZH67PU79h209buLnVuLSuzAwcP28cId9r/1SA43+187TU88XmhPjV5l3yxabSUHD9ltQ1e50PMvui6wndu228yZc23tV5/ZtR6P1AwwCau73mtXuj+UfNzhDueZaSPt3Oj+dnLuBLcPpQdL7OyED+3UvIk37J/mNeTxR7HQ9fr8AQBEgaFrrUWGrsXqnj17rFOnTnb8+HF37U2PHj3ctTiap28qdeMBTVcY0t3ZNJ0enebNlStX0up1140orl69mpdz5851hs2LorYvw+ZFkfrw+gMnz9snK0vszlEb7ceDV7nra174eof7+S+7LbbuM7fagsVrXO2Jo0fs2oEddvXsaVtbctp+1XOiffX5BLuuf57pg03nu6x63ACrnjTIqqcOsaq5o+1qRbmrvTD5Y6tav8iu7VpnVy9ftmuH97l5fl/0/Fr5sRr7522o449qoesrKpK3uQYAqA2CTmuRmxHEqoZO6JbSt99+u/361792QUcBRiFH1+X40FNSUmJPPfWUu0bnd7/7nW3duvWGdbVEGbqWG4auFa5ew7x0IwH9d379M03dIeyTVYdt6OpS+83nm9LDzv7q3RX2b/p85x7/2ZuL3D/mdP/Z/9Aeqyg9aGcO7jf7so/ZiplWuWmZXez37PcBZ9LgxPRvzC6dT221Jtr3M/t2Jm/ZrBsHiMzraTQv9Q82Mynk+ROFrmfoGgBEhaDTiuT20vGrXpsod1PTH3X9cQ6b1xIl6OSGoNO49cHrV3TR/ne7Su2lr7e4/2GTeVe0RydstyX7k//MU3W6wcD2Y8l/1mklu8wmDLQro3ratUFtvg82Cavb3GZHJwxJvDmOJpfNgfa94lgi4OhuaFmuo3HTW+g1NvWtJ+gAQFQIOq1N9dpoiBr/MBQbUIJObgg6jVu/5+TF5H/6TzBnT7n99/dX2E2dksHmf36y1kauK7VO3+61yVuPu2VcT4x6WBJBI/0/YRQ6hr9RI9zYZz3MvptqNnWonVu14MYbAmShsY8/k+ZeT9ABgKgQdBAxdgk6uSHoNF69/582Gnp25NyV9D/lfG7i1hp3V9MwNvdcvSy71iZd/W3yrmczh5uNeTsZboZ3sYrjx5yZ1Pb/YzyNefxhNPd6gg4ARIWgg4ixS9DJDUGnceoVbBRwNPzsH4avSw9P6zln1/f1+o//fgjZ5u/c0DT/zzlvsO+TbmhaY+1/Nlp7PUEHAKJC0EHE2CXo5IagE299enhZAE3rPn+fuwbH+5vPNtr4pTuS9eXlyQv+V882+/QN9/9t0oFG/8dmdD+zGZ+afdHbrHin2YHtyZsRJIh7/+tKa68n6ABAVAg6iBi7BJ3cEHTqVp85JCxYf+7yNXcNjvB3UdO1Ms9P2Zm+DkfO2n0yee1N6T6rOHLYzq9ZUDPcyE86uh4b18ujO57pZ+bd0BLUdf8zob5+9QQdAIgKQQcRY5egkxuCTt3qFVwqLiXvQKbQo9tD+3rdRU3D07TM2E1H3RA1fye1m4ess9Ebj9pdn2+yqqqq9O2hK8e/b9c7pYanTfk4GYBy3QEtg8Y+/kxaez1BBwCiQtBBzMP27ds3a8OOKU6bWtCprKy0Ll162Y9/dIs99ujzVlFxJjUnSXD+nXfcn9j/ktSccAg6jVtffPqSU6jHZsP+5HUyQndRU8DRMDXfg/PLkRvdndSEgpF6euzYQbNV36avv6nq+0fXu5MPjX38mbT2eoIOAESFoIOIsdvUgs60abOcYv36zTZ40DD32KN5mi4UckaOGO0eZ4Og07j1umuaFPvKL9minYft0LGTbtha8CYD/+fAVelA5Dh7Kql6bFbMTF57kwg6l2aMaFbHn0lrryfoAEBUCDqIGLtNLegouPheGvXmKOioF0fop55rGXp0otFY9eqJUZhZX3rWqefqufmzbgvtP/Vf5kLOP+88x/5V4vlfvbvCyi+k/o+Nrqs5XJS8g5qGpwXvorZiRqPtfzaor189QQcAokLQQcTYbepBR8PU/PA1P2zN9/houb59B6aDkGf//v1pd+3aZatXr7bi4uK8nDZtmjNsXhS3bNniDJsXxeZQv2X3fpu1brct2bzXfjJomeux+W8Dlrqf/88eC+1fvDHf/pc3FthTQ+fZku9W2oy1u61k7x4rW7PYLgzpYlVv/N4Fm8r+z1lVl3vs6lsP28Gd25LrboT9zyX19avfuXNn6lMJAJAbgg4ixm5z7NHxwSczCHmqq6vTlpeX28GDB2tMq4vz5s1zhs2LorYvw+ZFsanXX71WZWsPVVi7b3bb9B3HXLj53/sutT/rtsj13qwpKrNvtxy0wxWXrPr4Yasu2WVnThy360u+Nuv+QLLnpu+Tdv27Kcl1HtyVNLX+ht7/2qS+fvXnzp1LfSoBAHJD0EHE2G2O1+gE5yvoZPboBGHoWvz1+uee/s5quoOau7lAIuD4O6jp2hs3P/UPO8tKy9yyVrw9+X9w+jyeDDhvPWi2dXlynke3ij5TnnrSMs9fXWju9QxdA4CoEHQQMXabWtDxw9OCd10LDlELzucandqJu17X3ugaHP//cDaWnk/9k8/FLuS8v+ygm+5uKnBoj1UcP2Znd240K9rs/hfO9bbJHhyb8H5ymTCqq1MPWt75qyvNvZ6gAwBRIeggYuw2taATNwSd+tcfO3nK9eLoZgPBGw7o/+L4O6lN3nrchq057Oa7GwyU7DKbNsQuzh1r1V3v/f4GA9OHp9YcjaZw/NTnX0/QAYCoEHQQMXYJOrkh6Jy24iMnXbApO3vZqXDzm8832V8NWOFCziPjtqWWTqB/9Ll+oeu98eHmeqc7zaYOMev9eI1haVFoCsdPff71BB0AiApBBxFjl6CTG4LOadt56Lgt3n/a/V+cWbtOunAj//N7K+3JSTvMrlxOBpyqa8n/geN7b8b2twtLZ9qZfYllxNHcwwzDaArHT33+9QQdAIgKQQcRY5egkxuCzmlbtrvMXYczY+cJ15OjkDN+81Grqr6evJ6maJMbpmYTP0j+H5zOvzHbk5iWqk9vP3DtTVTi2H/qC1dP0AGAqBB0EDF2CTq5aY1BRzcakLre5tCxk9Z11o50L478/727xM5eqDQ7kTivJ0u/v4ua7JQIOof2ptbUPI8/CPX1qyfoAEBUCDqIGLsEndy0tqBzpep6jZsNrC46Yv/9/RXu/+L8+zdn2ZBZ66x0x3azRROT1+F0uz8ZcNbMSfbYZFyD09j7nwn1ha0n6ABAVAg6iBi7BJ3ctLago/+LM3bTUddz89vPN9v/q1fyttGPfL7WyrZvTd5oQMPTFG66PWA28EWzZdNS1TfS2PufCfWFrSfoAEBUCDqIGLsEndy0hqCjIWrqyRHqxdHd1Pz/xflf3lxo7y7YbQf2Jd4nug5HAUdBZ8H47P8HJ0Bj7H8uqC9sPUEHAKJC0EHE2CXo5KY1BB3dTU09OeLz9UdcwOk6b7+7lfR3u0rtdHl5sidHIaf/s2Yny9yyUWiM/c8F9YWtJ+gAQFQIOogYuy0x6Ozduzftjh07bPny5VZUVJSXU6ZMcYbNi+KGDRucYfOi2FD1W3fusZ17imxz4ufwRVts4YZdbtpPBi1zQWfD9j12YNtmV7tt2SK73OdJq+50p5VsXH3DunLZUPsfVeoLW79169bUpxIAIDcEHUSMXXp0ctMSe3R0W+hNZefcndV0PY5uHf3/GbDC/nbwKhdyXp6+Jzks7dAeqzhWZpempIaszf4itYboNMT+1wXqC1tPjw4ARIWgg4ixS9DJTUsMOhqSpruqPTtlpws2f/bmIvvnnefYD7tOsYfGbkvePW3zd2YTBtrVTzp/P2QtwjU5mTTE/tcF6gtbT9ABgKjctGvXLkPE1mVYOIlTgk5uWlrQUW/O0gMV7oYDCjl/P2SdLS+usBU7DroeHLtw1mzPhhr/G+fauy/kFXJE3PtfV6gvbD1BBwCiQo8OIsYuQSc3LSnoHD9/xXYev2B3fb7JhZw/TtphFZeumV25bBf27zSb84XZp298f/vo1bPdjQiayv7nA/WFrSfoAEBUCDqIGLsEndy0pKCjkDNgaYkLOY9P3O6mKeRY6T6z8QPTPTj2/svJaQni3H4+UN+86wk6ABAVgg4ixi5BJzctJeioN6f7/H0u5Pwf/ZYme3LOlJsVbTLrnRqmpoCTQVzbzxfqm3c9QQcAokLQQcTYJejkpiUEnX1lJ2zx/tPu7mr//f2VVrZ9a/J/4WxcYtb9gWTIGfGm2dEb3wtNYf+pb771BB0AiApBBxFjl6CTm+YcdPRPQA8dO2lzth62/zxgpevNWbYzcS62r0z25OiGA51/Y7Z1efJOayEUcv8F9c27nqADAFEh6CBi7Da1oFNZWWlduvSyH//oFnvs0eetouJMak5NNP2VVzon9r8kNSWc1hp0rlRdt61Hz9vyPWV288erXcj5Yu0hs8NF399sQK6enaoIp1D776G+edcTdAAgKgQdRIzdphZ0pk2b5RTr12+2wYOGucdBfBi68477CTpZ0DU5+l85v/9ig93Uab51+XpjzZsOfNHbbOe61NLZKdT+e6hv3vUEHQCICkEHEWO3qQWdkSNGp8OLem0UdBRsgigIjRs72fr2HUjQSaAhaurB0T8CPXf5mu05edF6LNjvrslRT84/DV2W/B85I7slQ87bT5ldvpiqzk1j7H8uqG/e9QQdAIgKQQcRY7epBx313ASHr/leHoWf1h509M8/FWw0RE3qhgMfLD/kAs6/7jTD/izx83/rtdhKivYl0uGQZMj56p06/fPPhtz/KFDfvOsJOgAQFYIOIsZuc+vR0XNdv+MNu45nz549abdv327Lli2zvXv35uWUKVOcYfOiuH79emfYvCjmql+8caeN/m6r/Z/vfmd/2Xex672R/6HXPOs/cqrNWbrWJi5cY7u/neRCzuVej4euJ5cNuf9RpL5512/ZsiX1qQQAyA1BBxFjtzleoyNaQ4+OemxUe7L8VGrK9xw5l/y/OH54mrxl2Dr7zeeb7GzRDrMJA80+am+ly+batUFtkr05p46mqqNT32/0qW/d9fToAEBUCDqIGLtNLej4Gw0Ee2sUZhRqgj07rSHoaFha2fFy21x81F2Do2txdP2NbjTw7JSd7iYD/+2D1TZ+8zFbeqDCLl64aJVHDpp9+kYy2AT9rEdqrXWjvg1d6lt3PUEHAKJC0EHE2G1qQSdumnPQ0c0FFHK+21XqAs7ApQftrwassH/b5zvXg/OzoevtzJlEQ/LyRTt7IRECi7ebfdQuGWx0Lc62FVY5/n07v3ZRna7LCVLfhi71rbueoAMAUSHoIGLsEnRyU8igU3z6ki3aediGLy+yh8dtc+HmL/outX+TCDq/H7M5uZCGox07+P0/AFXImfJxcl7VNTtzcH9BG7rUt+56gg4ARKVVB50zZ85YeXl56DxEzF+CTm4KEXQ0NE3X4OhOago5/hqc/zlknVVcuuZ6evTTqquTt40Ohpw1c1JrSVLfhir11NennqADAFHJO+jozkNvvvmmHT16NOe02lTQ6N69u23atCl0fj7ql+CJEyfs7NmzofO9umvSu+++GzpP6xg1apRNnTo1dH7Qbdu2uePWNsPmI7Y2CTq5acygc/FKle0rv+RuE/0Pw9fZXw9e7QLOn3VdZDN3nkwtFeBMudmA58063xUackR9G6rUU1+feoIOAEQl76Cj26u+9NJLVlZWlnNaFBV2zp8/HzovH9UI6dGjh9ufsPneXEGnpKTEXnnlFevSpUutvT7ad3qGEL+XoJObxgw6ug5nxs4T9i+7fX+r6P/+/gobtWJfaokEF84mA86Vy2bThyUDTp8nzBZPSi1Qk/o2VKmnvj71BB0AiEqDBR39Ilq+fLk9+eST9oc//MFGjx7teljU26MQooChXpBjx47ZBx984HqDZsyYYY8++mjaTp062fHjx13oeO211+yhhx6yt956yzUwtD0tP3z4cOvcubPdfffd9vnnn1tpaam1bdvW7rzzTnv66afdevft2+eW0Tpff/31dH2uoDNv3jzXo6P5q1evdtO073379rWioiJ3LNrv2bNnu23osX5xK/Co5r777rMXXnjB/a+AzHUjtnQJOrlprKCju6qtLz1r/2XgShdw/jR9j/upa3QOHUv15uiGAttXmq2caTbizWTIeecZs6PFyeATQn0bqtRTX596gg4ARKVeQUch5ptvvrHFixc7x40bZ88++6wLOpr/6quv2sGDB62iosLee+89F0w076mnnrK5c+e6npCw3heFiMGDB9v48eNdcFCvypIlS9wvNzUOevbs6dap7bVv394NGdN6O3To4EJIcJ26DmfQoEG2Zs0at24Fk48//tg9zhZ0tO7evXvb5s2b3TIfffSR27bmaT/69+9vixYtckPutC1tR9vT45kzZ9qIESPc8qp///333S/0zG0gtmQJOrlprKCj6278LaPfX3bQPR+98ai7vbSrV5DZuMSs82+SAUcO+lMy/FRdS63lRqJuPxvUU1+feoIOAESlwYLOpEmT7Kuvvkovr6DRr18/O3TokOv18cEmLOhMnDjRBR0Fnl27drleHD80TD08Cj7FxcVuez6oBNeTuU6tZ926dfbpp5+6Wl+TLegooCjoKPAcOXLEunbt6nqVNE/rUnh5+OGHbefOnW6atuODjo5TQW7atGnuWIPrRWwtEnRy09BBR/8UVKw5eNb9889bhq13zz2qrThWZrZ+YTLkdP5tIvAsNjuZmBaB+jZUqae+PvUEHQCISoMNXVMIkX7exo0bXXhQD0+uoKML+9u1a+eW8+v0IULPT5486Ya8qecmStA5d+6c68EZM2aMa5ioR6e2oPPll1/aXXfdlR5Cp8cayqZ5+gU7dOhQNyzOh5/MfVQYU4+Vht6pN0j74NeN2Bok6OSmoYOObiF9qKIy2ZvTeb67EUGaM+V2buMyu/DdjO9vOFCUuq10ROrbUKWe+vrUE3QAICoNFnR0bYq/kF+/lHT9jAKE5mULOgo3CjkKO36dCg0dO3a0rVu3uucbNmxw19lovVGCjup1fY56hrQf3377bc6gox4cBRQFKT9NIU3rUw+PrtfRkLVZs2a563LUw6Pt+KCjQLVw4UJXpx4drUvr9OtCbA22xKBz/fr1tPr9o99X1dXVeakvTmTYvChq+zJsntxw+Iy9+12xCzl/P2Rdcvq1a1Z9LLHP6+Zb9Zv3JQNOp7us+tDeG+prs7bt1yb11NenXl8eAgBEocGCjgKAhq49+OCDbpiXhq3pF1uuoKPhbr/+9a/TPSm6mF8X+mvY2eOPP+6mPffcc+khY9mCjn4Jauibhtbt3r3bDYW799573U0RtM4+ffq4ZcKCjoKM9jXYC6P9VrjSzRUUxBS6dHzvvPOOCzXapg86avz86U9/cvv6wAMP2OTJk13ACm4DsaXbEoPO/v370+qLk1WrVrnjzEfdtl6GzYuihtfK4LQNO4tsz77EvF377NZPkjcf+Le9Fts3a3dZyY6tdmjzWjuydLZVvfF7q+pwp53+sLMdm/91jXVENWz7dZF66utTv2PHjtSnEgAgN3kHnagqEOiGAGHz6qLCgrq6w+ZlM7jduPYjqtrXOG+ZjdicVGOkJaMvNZrS0DV/dzUNUev87V4Xch6bsD35D0DFsYM1/gHo+ZVzktfo5LjhQC4yt19XqKe+PvUMXQOAqDR40EHE1idBJzdxBR3ddODc5Ws17q6mkPNfB676PuTozmqH9ph9+kZyuNqaOfVuaFJPfSHrCToAEBWCDiLGLkEnN3EFnePnr7ienAFLS1zI0d3VJm09nlyoujr589RRswHPJ0POsNfcpPo2NKmnvpD1BB0AiApBBxFjl6CTm7iCzs7jF2z85qP2590W27/vt+z7XhxxIrF/F86aLZ6cDDmj+7k7ron6NjSpp76Q9QQdAIgKQQcRY5egk5s4gs6xk6ds7Kaj9i+7LbJ/1X2xbSoL3IlK195ouJr7Pzl3mb32m+Q/AU1R6IYq9dTXp56gAwBRIeggYuwSdHITR9DZc/i4/fXg1W7IWo2QI85XmE0YmOzJ0T8ELd2XmpGk0A1V6qmvTz1BBwCiQtBBxNgl6OSmrkFHNx0Iokbix0uL3I0Hnpqw5fvrcYQer56dDDn9n01eo5NBoRuq1FNfn3qCDgBEhaCDiLFL0MlNXYPOoYrK9PU3usvah0v22n/sv8z+vNsiO1N+yqziRDLg6LqcFTPNut2f7MkJDFcLUuiGKvXU16eeoAMAUSHoIGLsNrWgU1lZaV269LIf/+gWe+zR562i4kxqThI913TNv/OO+xP7X5KaE05jBZ0j5664n1uPnnfD095fdjA5XK3zfBdyPltfluyx0fU4utFAcLja1uWuNoxCN1Spp74+9QQdAIgKQQcRY7epBZ1p02Y5xfr1m23woGHusUfPNV0o5PTtO9CFo2w0RtDx/wS0/OJVd/vof9vnOxdwZKcZ2634yMnkgkcS51o3HfioXTLkfNg2dLhakEI3VKmnvj71BB0AiApBBxFjt6kFnZEjRqd7adR7o2CTLcjUNl80ZNDR/8bxPxV03tP/yEmEm7/ou9S6zdvnhrCpkVhxrCw5NO2L3smAI4d0drW1UeiGKvXU16eeoAMAUck76Ozdu9cGDhxoHTt2bPbqOHQ8YceJiHW3qQcdDWPLHL4mNO2VVzqnlw1y9erVtCdOnHDHeOXKlbycO3euM3N6xflLtuHQafd49q5j9m96L0n34uw9fja93Mmdm+zC5E+sauFEF3Cuf/CqXdu1Pj2/No8dO+YMmxdF6qkvZH19QhIAtC7yDjotJeR4dTxhx4mIdbc59uhovkJOWAASJSUlaffs2WNr1661Q4cO5eX06dOdmdM37Sm2WRv22pKt++yng5e7gNN95habnZhWWrTbDpcUW+menXZu4Kvf9+IkPLp++Q3ryuX27dudYfOiSD31hazX5w8AIAp5B52wsNDcDTtORKy7ze0aHU1TL0+u4WpB4hq65u+k5tlYet4NVfM3HHh1RqpBd+Gs2faViQMZkryjWiLcXBnZPTlsrWhLcpk6UOihR9RTX596hq4BQFQIOgHDjhMR625TCzoKMJl3XVMPjm46UFFRkZ7nrS30xBF0Zs9b4K7B0Z3V1hw+a1uOnLeHx25LD1XrOm9/cuGqRBjSzQZ0JzX14HR/0CqnDE02FHU76eD/0IlIoRuq1FNfn3qCDgBEhaATMOw4EbHuNrWgEzdxBJ0BE+e7O6n91YAV6XAjfz58vS3dftDs7Cmz8xWpkHOX2Wu/NStK3hku3VDMI+SI+jY0qae+kPUEHQCICkEnYNhxImLdJejkRr05f9EzGWz+rNsie27KLmszdbv9afoe21d+0a6XJc6fhqnp/+K4kPMbs9J9qWoautS37nqCDgBEhaATMOw4EbHuEnRy8/zIZMjpMqcoeTtp9cwoyOh/4qgX59M3vr/ZQL8na4QcUeiGJvXUF7KeoAMAUSHoBAw7TkSsuwSd3PQaO99uHhj4Pzpnys1mf57svZEKOF/2TvbqnD6WWuh7Ct3QpJ76QtYTdAAgKgSdgGHHiYh1l6CTG3/XNdeTI1d9mww3bz1oNuAFs4/aJResOJH8mUGhG5rUU1/IeoIOAESlYEFn2LBhNnbsWBswYIB7PnjwYBs3blwN/fzMeX76qFGjajzP3EZdDTvOqKrhc/ToUTt+/LidP38+Pf3MmTNuulf/JO3cuXNuumqC6wiqeVpOjzPXEbaesPX5afqjcPLkyRr1ubbdEGpf9IfNP9djf3w6X9o/f960v+Xl5TXOo5bVNM3z06Q/9uA0LLwEndwo5CycN9fs0B6zFTO/vw7n0vnUErmpb0OReuqbcz1BBwCi0uhBp2vXru6ffalxqga3fmGtXr3a5s2bZ0eOHHFBQf95XD/VkJgyZYqtWbPG3epV86Wfrsa+bg2raVqP/lv5yJEjQ7cbxbDjjOoXX3xhH3/8sX355Zf2zjvv2NSpU13jfN26ddanTx8bM2aMc8KECW7/NV01YetSI+r999+35cuXu+dFRUWu9rPPPrO33nrL/cxcz/79+23o0KE1Asy3337r1B8U7dvw4cPT+7FkyZL0co3hjh073H7qnMgRI0akj6+4uNg9137quf4h3Ntvv+1qfL3eMwrHfhmv1qlzEJyGhZegkxsFne9mTf/+WhzdOjrjOpxc1LehSD31zbmeoAMAUWn0oKMeGH0zr8a6nusPvp5/8skn6fkKQfrpaxR0FGr8c6+maZ4eK0CVlpa6/1aeuVxUw44zqsEGt3ondDxqwGcLNLmCzubNm23IkCEuNAV7KxQMP/zwQ/fTT/Pr0XIKeTt37nTT1RBT8FEA0h8UhQSFBV/X2Oq10j4ojCqYfvDBB+411h+sDRs2uODml124cKELPpMnT3bzNY2g07wk6ORGv/eKhvZKhpyv3onck+Opb0OReuqbcz1BBwCi0uhBR41x9cJs3749dLhZvkFHlpSUuJAQXKYuhh1nVIMNbgU3BZV8go5+gauBv3XrVvvqq69qhJNcQUePV65cadOnT3ePFXh0rnUu9Qel0EFHvTgKbtoHvUbq8dJzBR89Vq+eltP+avrevXvd0ESFIk0n6DQvCTq5WTvxS7vc+W6z7g+kptSN+jYUqae+OdcTdAAgKgW5RufTTz+1gwcP2pUrV1yjPRhqsgWd6upqu3z5slNDmzRdQccPXVMvSmZdXQ07zqiqwR0cujZ37lz3y1iN8C5duljv3r2dEydOdMtnCzo6NvVmqCEVDC6ytqCjWp1bBS3VqV7T9QdFdRr2pn3o37+/7du3L72OxlLD6DRcbebMmW5Ymn4q9OicKRRqGQW00aNHu2AUPAaCTvOyJQadS5cupdVnUENKg9Pq4rLJX1llp7vtytoFofNrU7/zZNi8KFJPfXOu1984AIAoFOxmBFKNbjV0FVJ0wwFNyxZ0svXobNmyxS2r3g+tL3OZuhh2nFFVg3vp0qUuwGnImBp6mp4t0GSbriDgr+lRj8Z7773njlPzags6Cla6MYOmKfAo+Gi6wkGhe3SkXmuFOO2venL0fNKkSa7nSX+4tIx6d3TMOn6dR6n3A0GnedkSg05ZWVlafVGwcePGdIOtrs6YMcMZNi+Ku3btcobNiyL11Dfnen3+AACi0OhBR2PT1chVg13P9S2/GrlqxOp5XYNOcOhafQ07zqgGG9wahqXA4W9GEBZowqbruHXtkob1KcxIrUcNKs2vLehILasepeD1LU0l6OgPlPZNoVT7pucDBw608ePHu/l6PRXQ1EjWMeqaK4U9XWdE0GleMnQtN/o9KPNFnwOZL9RT35zrGboGAFFp9KCjmwb4u2mpsaBuaAUDPz9b0AkOXVPt7Nmzm2zQ0f6r50KBRdOCQ9f8sLHM6YMGDXI9HP66Gr9enSsN7VJoihJ0FCLffffddDiS+oMSHLom/RC6xlTHpR4af54y776m6Qo9PqBJzZs2bZoLOtr/Xr161TiPOvbu3bsX9LjwRgk6uSHoUE99/vUEHQCISkGHrjU1w44TEesuQSc3BB3qqc+/nqADAFEh6AQMO05ErLsEndwQdKinPv96gg4ARIWgEzDsOBGx7hJ0ckPQoZ76/OsJOgAQFYJOwLDjRMS6S9DJDUGHeurzryfoAEBUCDoBw44TEesuQSc3BB3qqc+/nqADAFEh6AQMO05ErLsEndwQdKinPv96gg4ARIWgEzDsOBGx7ja3oFNZWWlduvSyH//oFnvs0eetouJMak44BB3qqS9cPUEHAKJC0AkYdpyIWHebW9CZNm2WU6xfv9kGDxrmHmeDoEM99YWrJ+gAQFTyDjr6j/ZhYaG5quMJO05ErLvNLeiMHDE6sc8l7rF6cxR01MuTDYIO9dQXrp6gAwBRyTvo7N27t8WEHR2HjifsOBGx7jb3oKNhbJnD186dO5e2rKzM5syZYytWrMjL8ePHO8PmRXHhwoXOsHlRpJ765ly/ZMmS1KcSACA3eQcdRMRstsQenePHj6ctLi62iRMn2owZM/Lyiy++cIbNi+LXX3/tDJsXReqpb871U6dOTX0qAQByQ9BBxNjlGp3cMHSNeurzr2foGgBEhaCDiLHb3IIOd12rG9RTX8h6gg4ARIWgg4ix29yCTl0h6FBPfeHqCToAEBWCDiLGLkEnNwQd6qnPv56gAwBRIeggYuwSdHJD0KGe+vzrCToAEBWCDiLGLkEnNwQd6qnPv56gAwBRIeggYuwSdHJD0KGe+vzrCToAEBWCDiLGLkEnNwQd6qnPv56gAwBRIeggYuwSdHJD0KGe+vzrCToAEBWCDiLGLkEnNwQd6qnPv56gAwBRIeggYuwSdHJD0KGe+vzrCToAEBWCDiLGbksMOr5xJg8dOmQ7duywsrKyvFy8eLEzbF4Ui4qKnGHzokg99c25vri4OPWpBADIDUEHEWO3JQYd9eJ4Dx48aCUlJVZeXp6Xqpdh86JIPfWtuV5hBwAgCgQdRIzd1jB0TeYL9dRTn389Q9cAICoEHUSMXYJObqinnvr86wk6ABCVm3bt2mWI2LoMCydxStDJDfXUU59/PUEHAKJCjw4ixm5LDzrXrl1z5gv11FOff311dXXqEQBAbgg6iBi7LT3oAAAAQNOHoIOIsUvQAQAAgEJD0EHE2CXoAAAAQKEh6CBi7BJ0AAAAoNAQdBAxdgk62Vm/frP9+Ee3OKdNm5Wa2jhUVJyxV17pnHh9StzzwYOGuf24847709MagsrKSuvSpZfb1mOPPu/2QzTG9rXevn0Hun0QOuf+/Gv7Itv+xUHm9oOvf0NuP7hOqe2KsPdfY27fo203xvkHgNYNQQcRY5egE44acGrQ6acad2oAN2TACOIbkz5UqOHpG5qZjfG4UaPWN6r9dhtj+75Rr+PWujO34/cjbP/iIHP7et21br/9kSNGu31qiO0H1+nfdyUlh0Lff421ff0U/rz47TTE9gEABEEHEWOXoBOOGpVq3HrUuFPDrjHQtsaNnVyjceu3rUavGpe+IRo32k6wIavHDb19rXP+vMXuWLOFKL8PPnAI7YP2JWz5uhC2fb8t9VoEG/oNsf0gWpfWuWXLttD3X2NtX+uWCj06N411/ADQeiHoIGLsEnTCUWMus6EpGxo1Zn3jMVvQ8dMbCm0v81v8xti+1hkWdLT9bA3tYO9DfQluX8cbHJql7YcFjTi3r+1qfdqOthH2/mus7QdfZz1vjPMPAK0bgg4ixi5BJ5ywhqYafA2NGpQKGV41tseOnZzethqgWqahGpdat45VaJtqyE6aNK1Rtq9znhl0gvsjMhvamh9cvj4Et6/jDW5Xj2VDbV/rCl6TpZ9h77/G3L6GTgbfiw15/AAABB1EjF2CTjhqxPlvq9WQ899uNxbBbaqBqwal0PPMMBAn2o4PNX5bK1eubZTtB9ctfe9CEB84RPC8xEFw+5mvv9+Xhti+tquQoW15sr3/Gmv7QYLbaYjtAwAIgg4ixi5BJztqyAW/zW5Mgo1boQal9qOh77qmxq6/LiW4rcbYvtbrg0bw3Hs1zYcOPY/7rl/B7YvgPvgGfUNs359br19v2PuvMbfv0X405PEDAAiCDiLGLkEHAAAACg1BBxFjl6ADAAAAhYagg4ixS9ABAACAQpN30NmzZ4+98MIL9uijjzq7du1qmzZtCl0WEVuXBB0AAAAoNHkHne3bt9tLL71kZWVlduHCBdu4caO9/PLLVlJSEro8IrYeCToAAABQaGIJOnp+6tQp69Gjh5u+Zs0aGzp0aHpZPdY02b9/f3vnnXfs7rvvtnfffdfVaZmVK1fak08+affee68NGTLETp8+na5HxOYlQQcAAAAKTaw9Om3btrVDhw7ZsmXLXIjxy+qxpkmFGTWCFHC6devmws/x48fttddec9PPnj1rH3zwga1bt67G9hCx+UjQAQAAgEJTr6Dz+9//3h555BF78MEH7fHHH7ddu3a5ebmCTqdOndK9OH56RUWF9e7d2/r16+cCjsKOr0XE5idBJzeryqrsg3VX6qXWAQAAANmJpUenvLzcXn/9dduwYYObV9ego8fnz5936xw+fLg99dRT6dCEiM3P5h50Ju26ag9Nu1Rney6/nFpDds5evm5/+cn5WNS6AAAAIJzYrtFZsmSJ9ezZ0/XOaBibrtfRY/XO6HGuoKNGkR5rCJumjx492iZNmpTeFiI2Lxs66GQ2+IPkmheVD9ZeuWE9UXwwEXZqQz0xWlbbyMaOk9XObPj9o1cHAAAgO7EFHYWa7t27u8CjIKPHGtL29NNP28MPP5wz6Ogan4kTJ7rlNRTu1VdftYMHD9bYHiI2Hxsj6ChUqMGfGRj8NM3Xcvngg0RdjSPoqJfm5tEXnNl6bPz+EXQAAACyk3fQiaLunKYQEzYvTA1f425riM3fxgg62YKCx4eBfDh8rtqFiLqaqxfGo+Vy7X9w23ocBkEHAACgdho06CBi67S5B52GpLagEwWCDgAAQO0QdBAxdhs66DQ0PkjU1boOXdPQtOdmV6bm1M6z31a6GoIOAABA7RB0EDF2CTrZCQadul5H5LdB0AEAAKgdgg4ixm5zDzqNdY2OemfUSxMVenQAAACiQ9BBxNjlGp3sBINOvhB0AAAAaoegg4ix29yDjq+tq3HcXlq9SasTy0juugYAAJA/BB1EjN3GCDoP6VqVdVecQRQCNE3ztVw+KEC49dTRSbuuptaQndqCjoam/f3oC049DkO1BB0AAIDcEHQQMXYbI+gEDZJrXlOgtqAjdK1Prut9CDoAAAC1Q9BBxNht7jcjUM+MhqHV1Z7LL6fWkB310gSDWL7+txHZe3wAAACAoIOIDWBzDzoNjXpiOiysDA1LUVQtvTkAAAC5IeggYuwSdAAAAKDQEHQQMXYJOgAAAFBoCDqIGLsEHQAAACg0BB1EjF2CDgAAABQagg4ixi5BBwAAAAoNQQcRY5egAwAAAIWGoIOIsUvQAQAAgEJD0Cmwp06dsk2bNrmG4fnz5920M2fOuOmZyyI2Fwk6AAAAUGjyDjrTp0+3pUuXpp/PmjWrxvMpU6bY8uXL08+lGvJffvmlLVu2zD0/ffq0M7hMc1XHduLEiXRYieL+/futT58+9tlnn9mYMWPs4MGDbvratWvt888/d49b0jnC1iNBBwAAAApN3kFn9erV9sUXX9iFCxdcQ/zDDz+0Tz/91M6dO+eeDxs2zHbv3n1DneZpGT1WOJKZyzRHjx49aoMGDXI/w+aHqcA3bty4G6YHg05LOkfYeiToAAAAQKHJO+ioIfPxxx9beXm57dmzxwWdTz75xI4cOWKHDh1yz9XDsWDBAheI+vXrZxs2bLAJEybY5s2b3c833njDqWUUmNatW2e9e/e27t272/z589204DYrKipcXc+ePa1v375ufcH5ClHalnqN3n33XTt27JgdPnzY7UvXrl1dz4kfErZ37163T2+++aZbXnWq1/GMGjXKTR88eLA7nuPHj9uIESPcMSukjR492pYsWZLe7r59+9z+dOrUyQYOHOiW99vVsQwZMsStxy8vdQ788Wvda9asccemeT7oRD1HWpeC5QcffGBz585NbyPzfKgHSdvS/vl90Db8cuql69Gjh1PD6bSMzpf2RefjnXfesW3btqXXj5hNgg4AAAAUmryDjhrHalyrQbNw4ULX6zB16lTXeJYjR450oUDT1QD3jWs1mtWQ1+Ngb4XC0kcffeSWU+NaIWrHjh3p7UkNhZs8ebIbHqZhXj5M+fnaJ/WqqMHue5YUvrZs2eICwTfffOP2UevXtvx0BQaFmpMnT6ZDjKavXLnS7a/WtWrVKheU9FPr1LqD+xbs0dE8rV/Laj3a7+HDh7ugFqwJHn+wFydbj062c6TlFX70Wmg5b+b5yOx18tvxy82YMcOdW4Upvba6Vkivrc65jmP79u0uEGUeB2KmBB0AAAAoNPW6GYGGXSkMqPGrRrgCjoKEGuZz5sxxy+ixb7RLPQ4LOlpeQ980JE7qsRrZvk6qsV1SUuJq1OuiHpngUDHfYPfrLyoqsvfee89dO6R1zpw50wWOXbt2uZCk3hstp30fOnSoW7eWV++JltdPhTSFKQUFHedbb73leoP8Nr3BEKHtqhfHhyHVa3vq6QrWBI8/GG6Cj6OcIy2vbfvteTPPR21Bxy/nz4em6zXVdUQKg6Wlpel1I+aSoAMAAACFpl5BR9eYqEGsBrdCg4ZnKYCoka9v/7WMGulRgo5+qtY34mVmD4XqfC+SwoRCSK6gowa7hpJpP/06t27d6oJOsFcmGHQGDBhgixYtSi+v4XHqwVDI0jAvDVHTsDS/TW8wRASDgubp3Kj3JfN4gsfvQ0fm4yjnSMtr23573szzkU/Q0XP1dOkcapmxY8e60KfpiNkk6AAAAEChqVfQUdjQt/0a2qTnagBryJp6Wvw1KWqcRwk66jlQr4e/hkb1mUOkJk6cmO4pUkNKISZX0FFPyvvvv++CjZ+v5TOnq1dK29aQMAUpPdd0bd+HGl2zonCkEKThbZmN/WCIUDDQY79+hT4NOfPH5g0evw8dmY+jnCMtr+35YOLNPB8KXNoPXauj5xqiV1vQ0bA3fz7Uo6PldO2TniNmk6ADAAAAhaZeQUcNZwWGjRs3pqdpKJWGh/kgoEZ6tqCjn/5Cey2vwKSL7DU8TL01mRfw6y5u/mJ59awoUAWHg2U22KV6ZLS8bmCgn/4GBuoN6datm5uuXhz1uKje36RAy2o/NGRL4cUHI+2nelV849+rWoUIrUuBSdf/9OrVy61H6wsb7hYl6EQ5R1omStCRulmBbsyg43777bdrDToKejomHYfOl4Kmerf8+hDDJOgAAABAoalX0IlDNd6D/3tGzzMb7EHVyM41P0xfE2ygq1dE29X2FHp0/U2wRsvX5X/iSK3/7NmzNZ7XdV/DrOs5qk3to9YRNi+b6jmq6/nA1itBBwAAAApNwYNOIVSDXdfb6Foi9Who+J0fZoaI9ZegAwAAAIWmVQYdr3p1NCxNt1EOm4+I+UnQAQAAgELTqoMOIjaMCjrXr19HRERELJgEHUSMTV2XJnVnv+rq6husqqpCREREbBQJOogYiz7k6EYXulvfpUuX7MqVK4iIiIgFMe+g0759e0RspoZ9puurDzm65k23PS8uLnb/Q2rbtm2IiIiIjS49OohYbxVydDdDhRz9fy0AAACAQkPQQcR663tz9P+d9A9zAQAAAAoNQQcR6616c/SPaNWbo2FrAAAAAIWGoIOI9dYPWztx4oS7EQEAAABAoSHoIGK9DF6fo6Bz6NCh1K8XAAAAgMJB0EHEeknQAQAAgKYIQQcR62Uw6OhGBAQdAAAAaAoQdBCxXhJ0AAAAoClC0EHEeknQAQAAgKYIQQcR6yVBBwAAAJoiBB1ErJcEHQAAAGiKxBJ0rk7+0KzNbQlvrYO3ubqw9SFi85GgAwAAAE2RWIJO3UOO97bQ9QW9VHrArs4cYVWDXk2r55oetjwiNq4EHQAAAGiKxBR0wkJMNMPW570yb6xbplrhZsYIu7x9jfup55p+Zf640Lo4PHnypGu8hc1DxO9tTkFn9+7d9uCDD1p5eXlqSu1cunTJnnvuOVu+fHlqCgAAADQHChN0Zgw327jYPQ5bn1TIud75N3Z53cLQ+Zqu+VoubH6mM2fOtAMHovUCVVRUWJ8+fWzz5s2h8xHxewk6AAAA0BRp/KCjkHO02KznI+552Po0LE3z1IMTNt+r+VqutmFsany99dZbtnTp0nRj7ODBg+kgU1JSYvPmzbM9e/a4Rpum6T+8nz171oUe9e5s3brVli1bZqdPn66xbsTWblxBRyHkhz/8od100032y1/+Mh1GFDAUNDp27HjDPB9CNF0Gw4iW0bLBGh90Bg4c6KZre5qWi8ygk20/M/dlzJgxOacDAABAwxJ/0OnzWM3nQTNCjgxb37WJg6z67adD52Wq5bR82Dzvxo0b7cUXX7QvvvjChZrnn3/eNTy+/vprW7Bggf3pT39yPT5PP/20e66at99+2wUhPf/Vr37lajVtwIAB6TCEiPEEHR9KfJjo2bOn+4wqJGhaMCBonvSPg8v54JIZTlSrZX1ICa7L12cjuC6/n2H1fhtCy2m6fmabDgAAAA1LvEFn6idmJ0rDw05IyJFh6/PX5ITNy9RfsxM2L6gPLmpgtGnTJt2bo+fqsSkrK7Np06bZqFGjaiyvoPPmm2+6aeoFeuONN1yNXy9iazeOoKMQEewd8T0vep5tXmlpaTqACB9IFCyC9UE0/fbbb3c/hWp9UMlGMOhkrje4vmCgCZJtOgAAADQs8ffohIWdLCFHhq2vMYOOhrM9/vjjpt6dDz74IGfQOXz4sHusdfj1IrZ24wo6fmiX1/fOZIYRHzb27t1boxdIKFAoWGhaMBx5MoNK5rrDCAadzPXqp9an9Qpt3+9/5n6FTQcAAICGo2Gu0QmGnRwhR4atzw1deyf60LUooahfv362adMm1zAJBh0FFz9cberUqQQdxDoaV9DJFjgyw4V/nm+PTn2CTma9ngd7iDyaHwxAnmzTAQAAIH4a7mYECjsXziQDT5aQI8PWF/fNCOSECRPs7rvvtpUrV9YIOgoyN998sz300EP2+9//3gUcTSfoIEazIa7RUVjx4UbTgj0h6h3xQ8H00wcVzfe9QGHr03L6TNcn6Pj1an0iuH099tO1nKbrZ7bpAAAA0LA0XNCRWxONjMFtwuelDFufdLeXfu23uW8vnZgf9fbSiNgwxhF0hAKKv5uZDyxCAUPhRGpeMJj4EBI2LCy4Ph+aNK0+QUeErVfop55n7ku26QAAANCwNGzQiWDY+rz+H4ZW6ZqdmSOscvtq91PPNZ2Qg1h44wo62YgSRgAAAAAyiSno3JYOLnXzttD1BdWwNH/DAa+eRxmuhogNb0sIOtqG73HJ1A+TAwAAgOZFLEHn6uQPXWgJDzPZvM3Vha0PEZuPDR10AAAAAPIhlqCDiK1Xgg4AAAA0RQg6iFgvCToAAADQFCHoIGK9JOgAAABAU4Sgg4j1kqADAAAATRGCDiLWS4IOAAAANEUIOohYLwk6AAAA0BQh6CBivSToAAAAQFOEoIOI9TIYdE6cOEHQAQAAgCZBLEHn1Wk77J91nm831UEtr7qw9SFi8zEz6Bw+fDj16wUAAACgcMQSdOoacryqC1tf0COnztnwlSX2m8822M2frHE/9VzTw5ZHxMbXB52TJ09aaWlp6tcLAAAAQOGIJeiEhZiohq3PO2fnUftX3RfZv+u31B4Zu9m6fLvb/dRzTdf8sLr6uGXLFlu8eLH7llqNNv0Mzj9w4ICNHTvWKioqakzPppaLuixic1VB5+zZs1ZeXm5Hjx5N/XoBAAAAKBxNNugoxGi+wk3Y/Jem7HDz4w47CxYssFGjRtmxY8fsjTfesIMHD9aYv3nzZmvTpo1r0AWnB505c6YLRHo8ffp0+/zzz29YBrElqS8Ezp0750K9hq+pV0efAURERMRCWZCg0+nbvTZ+yzH3OGx9GpamHptsIcersKPlahvGplDig4m+edY3zvqpMKNgo/Ci55rvg44abrqDlJ9eUlLienqWLl1aI+ho+rx582zPnj3pmrfeesstp2+41fALblvb0rzgNNXouoaFCxe6n5qO2JzUe1/vZb3nT58+7X65AAAAABSSRg86Cjnbj12w//fby93zsPUNW1nshqeFzQuqgKPltHzYfO/69eutX79+rjGmoNG7d2/btGmT/fGPf3S9Lx07dkz3uvigoyDy5ptvuuCxceNGe+KJJ+zrr7+2V1991Z5++mk3X8v+6U9/cuvQND3Xsi+++KJ98cUXLsD49enbbu3D22+/bRMnTrQXXnjBiouL3frvvfde69u3r40bN86tp6ys7IZjQGzqBsMOQQcAAAAKTexB5z+9u6LG86CZIUeGre+uURvctThh8zLVclo+bJ5XQ2lee+01d9vbzz77zGbNmpUeYqNQoR4WhRAtGxZ0+vfv76ZrfnDomtR1PFrHtGnTXJ2WUZjRcsH17dq1ywUq1Wi6rvNRGNL6n3rqKfdTDUUFHl+L2Nz0YYegAwAAAIUm1qDTZuYe23vyYmjYCQs5Mmx9Nw9ZW+uwNa+W0/Jh84Iq4KjnpVu3bi7wbN++3R577DEbM2aMCyLq5dFyYUEnGFyCQUcB6fHHH3c9PR988EHOoKPnmq5pfvonn3xSI+hk1iI2RxV2CDoAAABQaGLv0QkLO9lCjgxbX9w9OnLHjh326KOP2uDBg11DTOHDB5OVK1fmDDoKJFOnTnXzNeRNw9X8fC2v6Zrv16feIS0XXN/+/ftdQNL1Qdq+1qmeJYIOtkQJOgAAAFBoGuQanWDYyRVyZNj6dM3Nv494jY6Wq+0aHamham3btrXvvvvOPd+6dav9/Oc/t0ceecTuueceN0/LhAUdXUvz0EMP2ZNPPmm/+c1v3PU1mq9lb775Zjfv97//fbrHZsKECXb33Xe763X8+hRuNLztvvvus5dfftm6dOmS/ueKBB1saRJ0AAAAoNA02M0IFHZOXrjqAk+2kCPD1qcA8y+7Rbvrmpar7a5riNi4EnQAAACg0DRY0JFTt5+wvx+yLnSeN2x90v8fnTdCwo6CzctTG+b/6CBi/SXoAAAAQKFp0KATxbD1eRVi1GOj4Wl/GLvFhR791HNNJ+QgNk0JOgAAAFBoYgk6/ywkwERRdWHrC6reG12DoxsO6O5q+qnnDFdDbLoSdAAAAKDQxBJ0Xp22o85hR8urLmx9iNi8JegAAABAoYkl6CAiBiXoAAAAQKEh6CBi7BJ0AAAAoNAQdBAxdgk6AAAAUGgIOogYuwQdAAAAKDR5B52zZ89aaWmplZSUIGITVp9TfV7DPscNJUEHAAAACk3eQYeQg9h81Oc17HPcUBJ0AAAAoNDkHXTCGlOI2HQN+xw3lAQdAAAAKDQEHcRWYtjnuKFsDkHn+vXrdubMGbty5UpqSm603Pnz51PPAAAAoKlD0EFsJYZ9jhvK5hB0Ll26ZM8995wtX748NSU3Wq5nz56pZwAAANDUIeggthLDPscNJUEHAAAACg1BB7GVGPY5bijjCDoaWrZixQq744477JZbbrGpU6e6aevXr7fOnTvb888/bz/4wQ9s6NChdu3aNVdz9OhRe/HFF93yHTp0sBMnTrjpp06dsjfeeMNN13wt54NOnz597NZbb3WuW7fOLR9GMOicO3fO3nrrLfu7v/s7e+qpp2z//v1u+oULF9wy/+N//A974IEHbNOmTW763r177ZFHHrGf/OQnbj+0PwAAANCwEHQQW4lhn+OGMo6gs3v3bnvppZesoqLCBYg2bdrY9u3bXeB46KGH7PTp03b58mXr0qWLLViwwAWXV155xZYsWeIC0fz58+21115z+6PwoeeavnDhQlej63MUdD7//HOrrq52oapTp05Zr9nxQaeqqsrefvtt++qrr9z6tm7dak8//bTbn+nTp9snn3zipm/bts369u3rQpG2t3HjRjf9yy+/tG+++Sa1VgAAAGgoCDqIrcSwz3FDGUfQGT9+vAsIixcvduqxgoQChwKKgo347rvvXKAoKipyvTjavlCQefnll23nzp32wgsvpHt3FGoUPrRccOiaglXHjh3T683EBx0FmuD6FIy0b1u2bHG9Tb/97W9typQpdvz4cTdf4ebDDz90oU3ryLZ+AAAAiBeCTgNaXFzsGk/6Fjronj170suoQaiGmIa2BGuD84LLe/26pR776Vp23759NZbVenbs2FFjHzKX8apey/vnfjvBaVLPM7edOd9vM3hsYevz+xw2T9PDzlfYOcHchn2OG0q9TvVlzJgx1r1793TQkTqOzKDjA4jeO8GgojCjXiANH9Py5eXlbrpHy+UTdLSe4PrUw/Pmm2+6kCP0z1nnzp3rlnnvvffcfIWdQ4cOud4cBSG/TQAAAGg4CDoNqBrpkydPtpEjR9o777zj1GMNW9H8tWvXuiEwGuoycOBA17Dzjfw1a9a4aweGDRvmGkufffZZep6Gyrz77ruubvDgwU7f8NfyGpqjx16tq3fv3jZ8+HC3faltB5eRWofWO3v27PQ0hRR9G611BJfVc00PC2h+vt+mltM37rr+IWx9fp81T+dh0qRJ6QCl6ZqvxzpuzddzrUPXZhB4ohv2OW4o4wg6Cg66nkbD1oR6UBRCFBI0VEzbUYDQ50M9PQoYzz77rAvCQj0s6kVRD4wfOiZ0LgYMGOCGxOUTdHwPjt6bQv+M9cknn7QjR464z6mffuzYMbd+BRxdz1NWVuamL1q0yH0eAAAAoGEh6DSSarxL/1whSA12NZ70XA1DBRB9a615CjHBeVpWQ3QUAHRNwbfffpte17hx41xDT499aPDzZG2hxKv1KzQpnGgfNK0+QSc4f9asWW6/w9bn91nzFGS6deuWnh8MOjp/PoTpPHz66afpb/mxdsM+xw1lHEFHNxjQ5+Dmm2+2n//85/bMM8+4sKPPxQ9/+EP71a9+5eap18aHoQ0bNrjpt912m917773uPSX0U881/e6773ahJt8eHaHz+eCDD7r16SYGq1atctMVbh599FE3XTcqmDBhggtj+mzpGDT9zjvvdNsCAACAhoWg00hmBh0N6VIjTg0eP00XSysMhM3zqsE2ZMgQ27x58w3zZL5BR8Fh9OjRtmzZMhe4fNBQTRxBRwElStDRPDUOFbj0PBh0NBxIQSjbsWNuwz7HDWUcQcejwFNZWZl6lgwcCigKN8HpHgWLsOlC0zU/F7qD2v3332+333572q5du4auM9v6dJMEXQsUJNd+AQAAQPwQdBrJzKATFhR8o15BRz81T8NvFBD8cDNN88to2JaGu/meIK3Dhwa/TqltqZekR48eTgWl4HalwoPCldapQKFeIk3XcpnBRIbtf+b84NA1DRXS0LOw9fl9Ds774osv7Ouvv64RdBTG1MjVujSsT8HQD3HD2g37HDeUcQadTHzQydbzAgAAACAIOo1kWI+Oei127dqVnqaGu25ZG5ynBqMu6h87dmw6DCiQaIiO5ul6BA0L8+vOFnRyhRKpHhcNy1FoUhDS9UTablgwkbWtU/MHDRrkAtSMGTNccFEoCVtfWNDROVDvjXp3fNAJquN+//33XQ9U5jwMN+xz3FA2ZNDRNTK6o1ptPTMAAADQuiHoNJKZQUcNQTXg1Xvin6v3Q2P5M+fJiRMnpgOMelu0Lt+boYBUn6Cj63F0Yb++KVfAkKNGjXK9RPUJOn5+cB3+2HwPlL8eaeXKlTdsS8ehi761vI412HOl5/7Cb79NzG3Y57ihbMigAwAAABAFgk4jmRl0pAKF7hilOzJpSJl6L9RA9PPUo6FeC90JTT81TfM0vEyN//79+7vp+unvoqbpwWFq6klRcAhOkwpUfj80X2HD34BA6p8n6mJ/XSfkbxDga3Xjg8x19uvXz91VLbjOYBBSQFGY0vGpN0r7rF4r3X3KH3dm0NE0hRsdk57r+HW8/pxw17W6GfY5bigJOgAAAFBoCDqIrcSwz3FDSdABAACAQkPQQWwlhn2OG0qCDgAAABQagg5iKzHsc9xQEnQAAACg0BB0EFuJYZ/jhpKgAwAAAIWGoIPYSgz7HDeUBB0AAAAoNAQdxFZi2Oe4oSToAAAAQKEh6CC2EsM+xw1lSww658+fT1tWVuZuh37hwoW81D/olWHzolhaWuoMmxdF6qlvzvUnTpxIfSoBAHJD0EFsJYZ9jhvKlt6jc+rUKTt8+HDqWd3RP/mV+XL69GlnvlBPfXOuV9gBAIhC3kFH38aENaYQsempz2vY57ihJOjkhqBDPfX51xN0ACAqeQeds2fPEnYQm4H6nOrzGvY5bigJOrkh6FBPff71BB0AiEreQQcRMZsEndwQdKinPv96gg4ARIWgg4ixS9DJDUGHeurzryfoAEBUCDqIGLsEndwQdKinPv96gg4ARIWgg4ixS9DJDUGHeurzryfoAEBUCDqIGLsEndwQdKinPv96gg4ARIWgg4ix2xKDzu7du9Nu377dli1b5v5paD5OmTLFGTYviuvXr3eGzYsi9dQ35/otW7akPpUAALnJO+jo28zly5eHzkPE1i09OrmhR4d66vOvp0cHAKKSd9DZs2ePjR8/PnQeIrZuCTq5IehQT33+9QQdAIhKLEFHv3T0jwnXrVtnJ0+eTC9z/vx5t5yGefhfbJp+7tw5N03qsV8eEVuGBJ3cEHSopz7/eoIOAEQllqAzZ84cGzFihBvK9vHHH7sx7PpFNH36dBs1apQtWrTI+vbta99++6375TZ8+HCbPXu2G6M+evRowg5iC5OgkxuFnD1dnrBDI/rbxSUzzEr3peZEo9ANTeqpL2Q9QQcAolLvoHPixAkbOnSoHTlyxE3fuHGjffXVVzdMV8iRmj5kyBB3QaF6fNQDpJ/BdSNi85agk5s5E8fbzjb3m7W51Vnd5jY73f63tq/Hc7Z/WD87/c2XZvs2m106n6qoSaEbmtRTX8h6gg4ARKXeQefo0aP2xRdfuF9afrp6acrKympM90FHjzXMbcKECdavXz9bsGCB+6Xl14uIzd+mFnQqKs7YY48+bz/+0S125x33J/avJDUnSW3zM4mjR2fUtPk2cdl2+3DYBPuyR09b2PaPdqTN3enwI68nAlB55/vt+Cdvma2enQ4+9W0oUk99c64n6ABAVOoddPQHX0PRDh486KbrlqsaspY5/ZtvvnFBR40DDWXTcDX17gwbNsyFpeC6EbF529SCzuBBw2z9+s3usUJM374DrbKy0j0Xtc3PJI6gk3mNzsUrVbblyHkbu/qADRoz2/r3HmSDO3WxDW0eTvf6VCU89l57u7B4ilUcyX/7hW6oUk99feoJOgAQlViu0dm6dav179/fDVXTNTp+uNrq1avdtTmDBg2ynj17uqCjgKPeHC334Ycf2tSpU7lGB7GF2ZSHrqn3RsEmW5Cpbb5oiKATxrnL12xz6Rn7eOEuG/XOQJvZ9jk73+ZXydDT9hd2bGAHs6JkQKsLhW6oUk99feoJOgAQlbyDThTVGFCI0S8l3XhAd2ULWw4RW5ZNNegoxLzySmfXaxNGrvnqgfYWFxe7L3h0jWE+qodbhs3L5qEjx23NnlIbMGOdvdNncDr0XGmTCDyd7rfST/tZxfb1obWZ7tu3zxk2L4rUU1/Ieo0UAQCIQoMFHd1gQN9Yqjfno48+ss8++8wFn7BlEbFl2RSDjsKLQozCTBi1zT9z5kxa9ebs2rXLzp49m5f+msWweVHcV3zQlm7eawMnLrZRXbvZnjb3poa3/cLOv36/XZ42zM4fLAqtlWooyrB5UaSe+kLWa7g7AEAUGrRHBxFbp00t6Oj6my5demUdjlbb/Ewaa+haNoJDfzS8beOBY/beV/Psoy7d0jc00I0MLg98xWztXLdckPoOHaKe+kLWM3QNAKJC0EHE2G1KQUfhRSFGd1Tz6vmuXXvcTQcqKipC5zeFa3Syka2hWH7xqg2ev9Oe6fNlemibQs+17g+abV2eWoqGMvXNu56gAwBRIeggYuw25ZsRxEFTDTqeikvXbNbO43bf0O/szfY90oHHRnRL7PzRejc0qae+kPUEHQCICkEHEWOXoJObhg46HvXwjFpz2B5/f7qNbfeyu1vb1U532cXZowvaUKWe+vrUE3QAICoEHUSMXYJObhor6HiOn79ig+dts5dfe9/duOB621vt6tDX0/+AtK7Ut6FKPfX1qSfoAEBUCDqIGLsEndw0dtARV6quW/HpS/byZ0tc746GslW9/YxZ6b7UEtGpb0OVeurrU0/QAYCoEHQQMXYJOrkpRNDxlJ29bC98vszad+htF9vdYVWdflvnfzpa34Yq9dTXp56gAwBRIeggYuwSdHJTyKAjNhcftfdnb7EnXv/YLrT9dfJGBWvmpObWTn23Tz319akn6ABAVAg6iBi7LTHoFBUVpd25c6etXLnS9u/fn5dTp051hs2L4qZNm5xh86Ko2qVrNtqnc9bb7a9/bkXt7ndh5/S4D0KXzzSO7VNPfdi8KG7fvj31qQQAyA1BBxFjlx6d3BS6R8fX65+NTtt02H71xhe2vu0jyZ6dHg/Vet1OXNvPF+pbdz09OgAQFYIOIsYuQSc3TSXoiItXqmzd/hP24KBv7a323e2SH8o25ws3P4w4t58P1LfueoIOAESFoIOIsUvQyU1TCjpCd2TbV37JXp6yzW7rOMI2t0/17rz7bOJgj6aW+p64t19XqG/d9QQdAIgKQQcRY5egk5umFnQ8/h+M/m3vb+y99q+5sHO9891mW5enlkjSUNuPCvWtu56gAwBRIeggYuwSdHLTVIOOUO/OusPn7NfDVtkDHT+04+0SQUe9OyO7pf/BaENuPwrUt+56gg4ARIWgg4ix21SDzvr1m23woGGpZ99TWVlpXbr0sh//6BZ77NHnraLiTGpOOC056HgOVVTaJ0v32T92HZP+B6Oud6doc6NsPxfUt+56gg4ARIWgg4ix2xSDzrRps1yQCQs6midFtjAUpDUEHeFuVHD4nL381Vp7qsN7dr5N8kYFl8e/bxVH8j/+xtr/bFDfvOsJOgAQFYIOIsZuUws66qFZvmxV1hCj6cGg4x9no7UEHU/FpWs2Zk2x/a7HWFvS9gkXdqo7/8bsu69TS9SNxt7/TKhv3vUEHQCICkEHEWO3uQ1dE7l6fMSxY8fS6vg2b95sx48fz8uZM2c6w+ZFce/evc6weVHMp/7I0WM2b0uJPTfyO3uqwwDb1/Y+u97mNqsc2cNOHDwQWpPNQux/UOqbd31xcXHqUwkAkBuCDiLGbnMLOpoW7NHR9Tq6bifI+fPn05aVldmePXtqTKuLs2fPdobNi6J6k2TYvCjWp/7AsdP23pyt9vd9Z9nMts+lend+a5VrF4QuH2Yh919S37zrFXYAAKJA0EHE2G2OQUfzxIEDJda378Abgk6Q1jZ0LZOT5adsW8kxe/azZfZsh3ftZPvUndnG9k/fmS0Xhd5/6pt3PUPXACAqBB1EjN3mEHSCgUbX8Ohuaxq6ducd97t5uWjtQcfXF5++ZO/M323/+MYY29Dm4dSd2X7r7syWi7i2ny/UN+96gg4ARIWgg4ix21SDTlwQdL6v140K5uw6YX8cOt+e6PCeXWzzq+97d0r3uWUyiXP7+UB9864n6ABAVAg6iBi7BJ3ctKSgI6qqr9vx81ds0NIS9393dO1OdZtfWFWb28w+7Zo4YUdTSyaJe/t1hfrmXU/QAYCoEHQQMXYJOrlpaUHHo/+7s7n0rHX9er090e8rW9j2j8neHfnVO+nA01Dbjwr1zbueoAMAUSHoIGLsEnRy01KDjudK1XUrv3jV+szcbE+9/mH67mzOOV+4fzbalPe/NqgvbD1BBwCiQtBBxNgl6OSmpQcdj3p4thw5b22/3moPdxnqblhQnQg7VzreZZemDLlhSFtUGmv/s0F9YesJOgAQFYIOIsZuSww6VVVVaU+ePGkHDx606urqvJw3b54zbF4Uy8vLnWHzotjY9ZVXq2xT6VnrPnmN9ev8lgs8119N9vBc//ojq75wNrQum429/5lSX9j6c+fOpT6VAAC5IeggYuy2xKCjY/Lu3r3b1qxZYyUlJXk5bdo0Z9i8KG7dutUZNi+KhaovOlBi8zbstWc+XWhPvDbIlrR9wq61uc0ud7zTKsYPskN7dobWZVqo/fdSX9j6Xbt2pT6VAAC5IeggYuy2xKAThKFr9avXPxxdsrPMPp6/3Xp0fdf2tLnX9fBUK/RM/LDWfzpa6P2nvrD1DF0DgKgQdBAxdgk6uWntQcfX67bUpRWX7MNE4Hm5+8epa3h+4a7hsdmfZw08cW0/X6gvbD1BBwCiQtBBxNgl6OSGoFOzXoFHd2n7fNlea99tcCrw3Gbn33jQbO3c1FLfE/f26wr1ha0n6ABAVAg6iBi7BJ3cEHTC6xV4DlVUuh6eAV372Pk2v0oOZ3vzAbOizamlWu7xR6W11xN0ACAqBB1EjF2CTm4IOrnrFXjKTp+3ARMWW+/OPV3gudzmdivv/phdXDbLzhzY3aT3vzaor189QQcAokLQQcTYbapBZ/36zTZ40LDUsxupqDhjr7zSObH/Jakp4RB0Gqde/3h0w6EzNnjCApvT4Tk70uZu18Oj21JXvvei2bYVqSXrRmPtfzaor189QQcAokLQQcTYbYpBZ9q0WfbjH92SNehUVlZaly697M477ifo1EJj1yvwnE8sP319sXV/51Mb0+5PqWFtt9q1buHX8eSisfc/E+rrV0/QAYCoEHQQMXabWtBRT83yZaty9ugoCI0bO9n69h1I0KmFQtaXnb1s78zbZU8Pmm5d2vd0vTxX2/zCLrxxv9mUjxIvztHUktkp5P4L6utXT9ABgKgQdBAxdpvb0DU/Xb062YJOWVlZ2n379tnGjRvtyJEjeTljxgxn2Lwo6h8myrB5UWwJ9Zu27bRp64vslZELrV/n7u5/8WhIm4a2XXjrD1a+emForWwK+099/vX6/AEARIGgg4ix29yCjqZpWJv3sUefd71AQS5dupT26NGjrrGlYJSPc+bMcYbNi6K2L8PmRbEl1Z+9kHg9yitswOwt1rb/aBvb7mU3rE29PGd6PG5XNyzOWZ+P1Be2vry8PPWpBADIDUEHEWO3ud6MQI0ohq7VTlOtv3ilypYVn7Yh4+fbZx07uMBzRXdr6/aYXR73fnpYW0NtPyrU16+eoWsAEBWCDiLGbnMIOgozCjUKNx6CTjSaer1uXrDz6DkbPXu1ffV6p/SwtquJ0HP4s4FWceRwk97/2mjt9QQdAIgKQQcRY7epBp24IOg0j3r9P57T5y/Z+wt2W+cPJ9mStk/YtTa/cMPaSt5+1U4unml26Xxq6eg01v5no7XXE3QAICoEHUSMXYJObgg6jV9/7vI127a/zEYP+dxmd3jODWurSgSeAx0fsq0TvqhT4CnE/gdp7fUEHQCICkEHEWOXoJMbgk7h6jWsbc/h4/bpvM02ddBgO5b6J6QKPtt7tbGTi2bUGnoKuf+itdcTdAAgKgQdRIxdgk5uCDpNo76qqsoOlZTad8M+su9ef8mFHV3LcyHxc9VbbW3j1Elmh/akqr4nru3nS2uvJ+gAQFQIOogYuwSd3BB0ml59xaVrtmT7IZsyaLCt6Pp96JGH33jUyqaPSbzw3LVNFLqeoAMAUSHoIGLstsSgc+XKlbTHjx+34uJiu3r1al7OnTvXGTYvitq+DJsXReprry8+fMy+HTvRxnbtYkfa3O0Cz+U2t9uG15+yuZ9/0eT3P5fNvb6ioiL1qQQAyA1BBxFjtyUGnYMHD6bdu3evrVu3zvXq5OP06dOdYfOiuH37dmfYvChSH71+z54iW7xyo/X+cJx927Wdu6ZHNzEoa/tPtqBHJ1v2xUibs3JLaG02G3P/w2zu9fr8AQBEgaCDiLHL0LXcMHStedbrzm0XK07b8qGDbGuXp9ND2y62/ZUVtbvPvnm7t61bvTG1dHYKtf+e5l7P0DUAiApBBxFjl6CTG4JO868/fuy4nSjaYxunTLRVg9+2wx0fcKGnss0vbW+7B2xGjy42f+o3dub0jcOsmsL+N+d6gg4ARIWgg4ixS9DJDUGn5dVXXb1qx7ZttlUfDbA9rz3qQo+GuF1KBJ81rz9rC97tZbs3bXHLni4vb3L7XxcKXU/QAYCoEHQQMXYJOrkh6LTw+qprdv7IYVs5fqytf6uNnWyfvJnBxUTo2dLxUdv85vP23ddfh/b2RKHB978WCl1P0AGAqBB0EDF2CTq5Iei0ovrqaquuvGi716+3HQO62qkO/5Tu7TnW5re2rsNj9lm//vbhmFk2Zd3+VFFuGnX/Qyh0PUEHAKJC0EHE2G2uQWf9+s02eNCw1LPsEHSoz6u+6prZmXI7tHKprR35kZV1ezJ9bY/UMLdxHdvYwCETbPWm3e5/+4RRsP1PUeh6gg4ARIWgg4ix2xyDzrRps+zHP7qFoBMB6mOqv3DW7Mplu7Z1pZ2fMtxK3u2QDj1yV7v77etur1vHEfNsyrbjNmd3uQs/sW0/TwpdT9ABgKgQdBAxdptb0KmoOGPLl62iRyci1DdQfXW1XTt2yMpmT7bdw/rbsdcedIFHt68+1/bX9lW7V+y9Dq/bmx9Nth6zd9qS/fntQ4Ptf0TqW0/QAYCoEHQQMXZb4tC1Q4cOpeUfhlLfGPWlB/bb8bXf2ZEvB9rB/u3SPT1X2t5uu9veZ++3f81e7PCO3fLGl3b/oFk2cN5227HvYOi6gjbW/mezvvX8w1AAiApBBxFjtyUGnStXrqQ9fvy4O8bgtLo4d+5cZ9i8KGr7MmxeFKlvhvWVlXb12CGr3LvFzo37wCp6PpkOPlI3N9jU9mHr3r67/UPPyfa3H662pydtt/6LD9jaklM11lWQ/Q9Y3/r69AYBQOuCoIOIsdsSg04Qhq5RX/D68nKz8xVmRVvMNi2xKxM/tPPdHnGhxw91W9b2cVvQ7in7ut2L9nK3j+zH/RfZ81N32Zg1B2xz8VHbfeKiVVVfT601OoU+foauAUBUCDqIGLsEndwQdKhvkPorl82Kd9j1b0aaje5n9uZ9NXp9itrfb4Pbd7JbOo20f9tpqt3Ueb79732X2sNjt9uodWVWfPpSakW5abD9jwhBBwCiQtBBxNhtrkEnKgQd6ptF/eWL7gYHVVevms37ymzAczWCz4U2v7L9HZLhp0OHPvb3nT6zn70xzv7Hx2vs3jFbrOOsvdZ74QGbX3TK9p5MrCtFo+1/Fgg6ABAVgg4ixi5BJzcEHeoLUq+hbuVH7OLccXZ57ACzj9rZ9QEv1gg/cmfHP9hrHXra33T60n7a8XPX8yP/6/ur7FejNtmXq/fb5PXFVn7hqhv6dvFKVWoDZleqrmf9/z+e+h4/QQcAokLQQcTYJejkhqBDfZOpr65O9vzoWp/NS82+GWHW+3EXeKrb3OZ+nuv0O9vT9Y+2/vWnbWzHNta+Yx/7Rafh9uedv0mHoDs+2+SGv/VfUmLPT9lpw1eXNtg/PCXoAEBUCDqIGLsEndwQdKhv0vW61mf7qmTo+fqj5JC3915IGuj5Od7+HpvXrZ1t7vK0u9X1X3WakA4+8t/1W2qvzy6yyduO17j+J2z73ebtt796d4X96x5L7MeD19iwNaWpOTdC0AGAqBB0EDF2CTq5IehQ32zrL1+08yvn2MX5E8w+bFsj+Fxt8wsrf+Mhqx74ks0YMsTu6/65/d87z0wHn3/ZfbH9etRGu3vUentkzCYbsfaIC0Dvfldi/99O461j+97Wr/0b9lKHd+z/0Wmmzd1bntpoTQg6ABAVgg4ixm5LDDqVlZVpjx07ZkVFRXbp0qW8nDNnjjNsXhSPHDniDJsXReqpj6X+TIVVnjzqpl3euc6qxg6w6v7P2vWu96bDz8VuD9rxvs/bzu7P2afdeto9nT5K3/HN+89fm2f/s9MX9kzHATar3TOurrjtPdZ14uobti1PnjyZ+lQCAOSGoIOIsdsSg05paWnaffv22YYNG6ysrCwvZ8yY4QybF8WdO3c6w+ZFkXrqG7L+yOFDdmLdUjs7ZZhd7fdUwqftWo8/pMOPPNvjUdvVr4N9MPgzu7XzKPuLzlPsbzt+aaPat0kvM+HdAaHr15cMAABRIOggYuwydC03DF2jvlXU60YHZ8qTP8Wl88l/bjqqh1W9/XSN4OOtSt0AQW4Z1DNZlwFD1wAgKgQdRIxdgk5uCDrUU5+oLz9itm6+Xen6QI2w470yNfyf9xJ0ACAqBB1EjF2CTm4IOtRTH6hfNi006Ni+LakFakLQAYCoEHQQMXYJOrkh6FBPfUb9kq/NPnjFrM/jZp90dEPcskHQAYCoEHQQMXYJOrkh6FBPff71BB0AiApBBxFjt6kFHd0SukuXXvbjH91ijz36vFVUnEnNSRKcf+cd9yf2vyQ1JxyCDvXUF66eoAMAUSHoIGLsNrWgM23aLKdYv36zDR5U8yJnzdN0oZAzcsRo9zgbBB3qqS9cPUEHAKJC0EHE2G1qQUfBxffSqDdHQUe9OEI/9VzL0KMTDeqpL2Q9QQcAokLQQcTYbepBR8PU/PA1P2zN9/houb59B6aDkKe4uDjt7t27bc2aNXbw4MG8nDZtmjNsXhS3bdvmDJsXReqpb871+vwBAESBoIOIsdsce3R88MkMQp6qqqq0J0+etJKSkhrT6uK8efOcYfOiqO3LsHlRpJ765lx/9uzZ1KcSACA3BB1EjN3meI1OcL6CTmaPThCGrlFPfeHqGboGAFEh6CBi7Da1oOOHpwXvuhYcohaczzU6tUM99YWsJ+gAQFQIOogYu00t6MQNQYd66gtXT9ABgKgQdBAxdgk6uSHoUE99/vUEHQCICkEHEWOXoJMbgg711OdfT9ABgKgQdBAxdgk6uSHoUE99/vUEHQCICkEHEWOXoJMbgg711OdfT9ABgKgQdBAxdlti0FHjynvkyBHbu3dvjWl1cfbs2c6weVEsLS11hs2LIvXUN+f6EydOpD6VAAC5IeggYuy2xKBz9OjRtPv377dNmzbZsWPH8nLmzJnOsHlR3LNnjzNsXhSpp74517f0HmMAiA+CDiLGLkPXcsPQNeqpz79evToAAFEg6CBi7BJ0ckPQoZ76/OsJOgAQFYIOIsYuQSc3BB3qqc+/nqADAFEh6CBi7BJ0ckPQoZ76/OsJOgAQFYIOIsZuUws6lZWV1qVLL/vxj26xxx593ioqzqTmJNFzTdf8O++4P7H/Jak54RB0qKe+cPUEHQCICkEHEWO3qQWdadNmOcX69Ztt8KBh7rFHzzVdKOT07TvQhaNsEHSop75w9QQdAIgKQQcRY7epBZ2RI0ane2nUe6Ngky3I1DZfEHSop75w9QQdAIgKQQcRY7epBx0NY8scviY07ZVXOqeXzQZBh3rqC1dP0AGAqBB0EDF2m2OPjuYr5IQFILFv3760O3futJUrV7p/HJqPU6dOdYbNi6L+WakMmxdF6qlvzvXbt29PfSoBAHJD0EHE2G1u1+homnp5cg1Xu379etry8nJ6dKhPPas71Nevnh4dAIgKQQcRY7epBR0FmMy7rqkHRzcdqKioSM/z1hZ6GLpGPfWFqyfoAEBUCDqIGLtNLejEDUGHeuoLV0/QAYCoEHQQMXYJOrkh6FBPff71BB0AiApBBxFjl6CTG4IO9dTnX0/QAYCoEHQQMXYJOrkh6FBPff71BB0AiApBBxFjl6CTG4IO9dTnX0/QAYCoEHQQMXYJOrkh6FBPff71BB0AiApBBxFjtyUGnbNnz6YtLS212bNn27Jly/Jy3LhxzrB5UVywYIEzbF4Uqae+OdcvXrw49akEAMgNQQcRY7clBp0TJ06kLS4utsmTJ9s333yTl19++aUzbF4Up06d6gybF0XqqW/O9dOnT099KgEAckPQQcTYZehabhi6Rj31+dczdA0AokLQQcTYJejkhqBDPfX51xN0ACAqBB1EjF2CTm4IOtRTn389QQcAokLQQcTYJejkhqBDPfX51xN0ACAqBB1EjN2mFnQqKyutS5de9uMf3WKPPfq8VVScSc1Jouearvl33nF/Yv9LUnPCIehQT33h6gk6ABAVgg4ixm5TCzrTps1yivXrN9vgQcPcY4+ea7pQyOnbd6ALR9kg6FBPfeHqCToAEBWCDiLGblMLOiNHjE730qj3RsEmW5Cpbb4g6FBPfeHqCToAEBWCDiLGblMPOhrGljl8TWjaK690Ti+bDYIO9dQXrp6gAwBRIeggYuwWOugoqOhaG11zoyFrUXp0NF8hJywAiT179qTdvn27+w/te/fuzcspU6Y4w+ZFcf369c6weVGknvrmXL9ly5bUpxIAIDcEHUSM3eZ2jY6mqZcn13C1IPToUE994erp0QGAqBB0EDF2m1rQUYDJvOuaenB004GKior0PG9toYegQz31hasn6ABAVAg6iBi7TS3oxA1Bh3rqC1dP0AGAqBB0EDF2CTq5IehQT33+9QQdAIgKQQcRY5egkxuCDvXU519P0AGAqBB0EDF2CTq5IehQT33+9QQdAIgKQQcRY5egkxuCDvXU519P0AGAqBB0EDF2CTq5IehQT33+9QQdAIgKQQcRY7clBh3fOJOHDh2yHTt2WFlZWV4uXrzYGTYvikVFRc6weVGknvrmXF9cXJz6VAIA5Iagg4ix2xKDjnpxvAcPHrSSkhIrLy/PS9XLsHlRpJ761lyvsAMAEAWCDiLGbmsYuibzhXrqqc+/nqFrABAVgg4ixi5BJzfUU099/vUEHQCICkEHEWOXoJMb6qmnPv96gg4ARIWgg4ix29KDzrVr15z5Qj311OdfX11dnXoEAJAbgg4ixm5LDzoAAADQ9CHoIGLsEnQAAACg0BB0EDF2CToAAABQaAg6iBi7BB0AAAAoNAQdRIxdgk521q/fbD/+0S3OadNmpaY2DhUVZ+yVVzonXp8S93zwoGFuP+684/70tIagsrLSunTp5bb12KPPu/0QjbF9rbdv34FuH4TOuT//2r7Itn9xkLn94OvfkNsPrlNquyLs/deY2/do241x/gGgdUPQQcTYJeiEowacGnT6qcadGsANGTCC+MakDxVqePqGZmZjPG7UqPWNar/dxti+b9TruLXuzO34/QjbvzjI3L5ed63bb3/kiNFunxpi+8F1+vddScmh0PdfY21fP4U/L347DbF9AABB0EHE2CXohKNGpRq3HjXu1LBrDLStcWMn12jc+m2r0avGpW+Ixo22E2zI6nFDb1/rnD9vsTvWbCHK74MPHEL7oH0JW74uhG3fb0u9FsGGfkNsP4jWpXVu2bIt9P3XWNvXuqVCj85NYx0/ALReCDqIGLsEnXDUmMtsaMqGRo1Z33jMFnT89IZC28v8Fr8xtq91hgUdbT9bQzvY+1BfgtvX8QaHZmn7YUEjzu1ru1qftqNthL3/Gmv7wddZzxvj/ANA64agg4ixS9AJJ6yhqQZfQ6MGpUKGV43tsWMnp7etBqiWaajGpdatYxXaphqykyZNa5Tt65xnBp3g/ojMhrbmB5evD8Ht63iD29Vj2VDb17qC12TpZ9j7rzG3r6GTwfdiQx4/AABBBxFjl6ATjhpx/ttqNeT8t9uNRXCbauCqQSn0PDMMxIm240ON39bKlWsbZfvBdUvfuxDEBw4RPC9xENx+5uvv96Uhtq/tKmRoW55s77/G2n6Q4HYaYvsAAIKgg4ixS9DJjhpywW+zG5Ng41aoQan9aOi7rqmx669LCW6rMbav9fqgETz3Xk3zoUPP477rV3D7IrgPvkHfENv359br1xv2/mvM7Xu0Hw15/AAAgqCDiLFL0AEAAIBCQ9BBxNgl6AAAAEChIeggYuwSdAAAAKDQEHQQMXYJOgAAAFBoCDqIGLsEHQAAACg0BB1EjF2CDgAAABQagg4ixi5BBwAAAAoNQQcRY5egk5tVZVX2wbor9VLrAAAAgOwQdBAxdpt70Jm066o9NO1Sne25/HJqDdk5e/m6/eUn52NR6wIAAIBwCDqIGLsNHXQyG/xBcs2Lygdrr9ywnig+mAg7taGeGC2rbWRjx8lqZzb8/tGrAwAAkB2CDiLGbmMEHYUKNfgzA4OfpvlaLh98kKircQQd9dLcPPqCM1uPjd8/gg4AAEB2CDqIGLuNEXSyBQWPDwP5cPhctQsRdTVXL4xHy+Xa/+C29TgMgg4AAEDtEHQQMXabe9BpSGoLOlEg6AAAANQOQQcRY7e534zAB4m6Wtehaxqa9tzsytSc2nn220pXQ9ABAACoHYIOIsYuQSc7waBT1+uI/DYIOgAAALVD0EHE2G3uQaexrtFR74x6aaJCjw4AAEB0CDqIGLtco5OdYNDJF4IOAABA7RB0EDF2m3vQ8bV1NY7bS6s3aXViGcld1wAAAPKHoIOIsdsYQechXauy7ooziEKApmm+lssHBQi3njo6adfV1BqyU1vQ0dC0vx99wanHYaiWoAMAAJAbgg4ixm5jBJ2gQXLNawrUFnSErvXJdb0PQQcAAKB2CDqIGLvN/WYE6pnRMLS62nP55dQasqNemmAQy9f/NiJ7jw8AAAAQdBCxAWzuQaehUU9Mh4WVoWEpiqqlNwcAACA3BB1EjF2CDgAAABQagg4ixi5BBwAAAAoNQQcRY5egAwAAAIWGoIOIsUvQAQAAgEJD0EHE2CXoAAAAQKEh6CBi7BJ0AAAAoLCY/f8BBqy1mN4wa2AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='F:\\\\Applied AI\\\\Assignments\\\\28.Spoken Digit Recognition\\\\Tensorboard Results\\\\Task_2.PNG')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "K0kaYQ1jaNop"
   ],
   "name": "Speech detection Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_gpu] *",
   "language": "python",
   "name": "conda-env-tensorflow_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
